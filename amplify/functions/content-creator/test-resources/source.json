{
  "config":{
    "indexing":"full",
    "lang":["en"],
    "min_search_length":3,
    "prebuild_index":false,
    "separator":"[\\s\\-]+"},
  "docs":[
    {
      "location":"",
      "text":"AWS Accounts @ idealo \u00b6 idealo aims to provide everyone a painless way of creating and managing your AWS accounts in our organization. This project manages all our accounts using Terraform and automated pipelines. You can access your accounts at https://idealo-login.awsapps.com/start#/ . They can also be made available in the CLI by running aws configure sso . Visualisation of existing AWS accounts \u00b6 The AWS Accounts Overview Page in Backstage provides an interactive overview for all AWS accounts we have in idealo. Usage \u00b6 Precondition \u00b6 How to slice an account \u00b6 The idealo organisation has rules on how to slice your account. The details can be found here . Use Case and Environment \u00b6 Beforehand, you need to know for which use case and environment you want to create this account. This is important to find the related KOMUEB ticket id and to determine the correct organizational unit (OU). We differentiate between accounts which are related to a subdomain and sandbox accounts which are unrelated to a subdomain. SANDBOX: These accounts are not related to a product/subdomain. These are for playground/experimental/research purposes. Due to this, all resources in these accounts will be nuked every night automatically. These accounts are connected to the following product in the Verfahrensverzeichnis: KOMUEB-3188 - AWS Sandbox Accounts SDLC: Stands for Software Development Life Cycle. This category includes accounts for dev/testing/staging environments that are assigned to a product/sub-domain. Therefore, you need the KOMUEB ticket id of the associated product to order an account. Talk to your PO in order to find the correct ticket and let the PO create one if it's missing. PRODUCTION: This is meant for productive resources, i.e. things that are ready to use by your customers (be it internal or external). KOMUEB / Verfahrensverzeichnis / Product overview \u00b6 References to KOMUEB in this document can be understood as references to PDEKOM for preis.de users. The Verfahrensverzeichnis is our central product overview in Jira. All running products are listed here with related information like responsible colleague and GDPR facts (handles personal data). A KOMUEB ticket is automatically created for each AWS account and this is linked to the KOMUEB ticket for the product. A product can be linked to multiple AWS accounts KOMUEB tickets. (e.g.: account for staging and production). If you don't have a KOMUEB-Ticket for your subdomain please ask your product owner to create a suitable ticket. Access Management \u00b6 Access to the accounts is granted using AWS SSO, which is linked to our Azure AD. That's why the setup requires existing users and user groups in our Azure AD. Please ensure that you set up groups accordingly using the GroupTool . You are free to use any preexisting user group and don't need to create a group with specific naming conventions anymore. Creating a New AWS Account \u00b6 The entire account configuration is based on the aws-prod-org directory. The aws-test-org is for CST testing purposes only. Ensure that you have read the preconditions . Edit this project with your favorite editor, e.g. by cloning it. Create a branch from main with an appropriate name. The name should reflect the requesting team and product/subdomain. Copy the example folder ( examples/account/KOMUEB-xyz ) folder into aws-prod-org and rename it to match your KOMUEB ticket (issuetype product!) id (e.g. KOMUEB-1234 ). SANDBOX: If you want to create a sandbox account, which is not related to a product/subdomain, please add your account request to the KOMUEB-3188 directory in aws-prod-org . SDLC: If you want to create an SDLC account, please use the corresponding product KOMUEB ticket id as described in the preconditions . Rename the Account Name directory inside to match the account name you want to request. Edit the terragrunt.hcl file in the directory you just renamed in step 5 and fill in the inputs. For detailed explanations on the variables, please refer to the module documentation . Commit & push your changes, then open a pull request . When opening a pull request a template for the description will already be pre-filled, which you should simply fill out in the appropriate spots. After your pull request was reviewed and merged you will receive more information on the next steps. Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ . Updating an Account \u00b6 Updating can be achieved in a similar manner as creating accounts. Simply find the account configuration that you want to change, edit the variables and make a pull request out of it. Please note that renaming an account is not allowed. Moving an account to a different directory (e.g. by moving to a different KOMUEB) will require manual steps by the Engineering Experience Team to move the backing state file of the module instance. Otherwise, the workflows will attempt to create a new account, but fail due to duplicated names. Changing Azure AD group names \u00b6 When changing the name of an existing Azure AD group that is assigned to a permission set in your configuration, there are certain steps that must be followed: Remove the assignment completely from the configuration, commit, and merge the PR Add the assignment with the new group name, commit and merge the PR This is required, as you may receive an error message stating that the group already exists if these steps are not followed. Closing an Account \u00b6 Closing an account can be achieved by deleting its configuration from this repository via a pull request. For a detailed step-by-step guide, please visit this page . Using Managed Account Budgets \u00b6 AWS accounts created with this process get a managed budget incl. alerts. Sandbox accounts default to a budget of 200 USD and non-sandbox accounts to a budget of 2000 USD. You'll get three alerts alongside your budget out-of-the-box: Your actual cost is greater than 80% of your budget Your actual cost is greater than 100% of your budget Your forecasted cost is greater than 100% of your budget You'll get automatically notified via email. You may control the amount of your budget via the account_budget property of the aws-account module. This property can be updated later on. You may control the recipient's email address of alerts for your budget via the account_budget_email property of the aws-account module. This property can be updated later on. Login to an Account \u00b6 Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ . This UI will provide you with access to the management console or programmatic access with temporary credentials. You may also access the account using the CLI command aws configure sso . This command requires AWS CLI v2. If you still have v1, you will need to uninstall it (having both is not really recommended as they both use the same command, aws). Info v1 (for uninstalling) https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html#install-macosos-bundled Info v2 (for installing) https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html AWS Account Credentials \u00b6 There are several options to handle your account credentials for the AWS CLI. For easy CLI access you can use aws-sso-util or go-aws-sso SSO Start URL \u00b6 ProdOrg \u00b6 1 https://idealo-login.awsapps.com/start#/ TestOrg \u00b6 1 https://idealo-test-login.awsapps.com/start#/ SSO Region \u00b6 1 eu-central-1 \u00b6 aws-sso-util \u00b6 After you have installed the tool, you may want to add the following environment variable definitions to your shell profile (e.g. ~/.bashrc or ~/.zshrc ) 1 2 export AWS_DEFAULT_SSO_START_URL = \"https://idealo-login.awsapps.com/start#/\" export AWS_DEFAULT_SSO_REGION = \"eu-central-1\" With that done, you can import all your SSO accounts roles like shown in the command below. This will create profile names like foo-account.admin or bar-account.readonly . ProdOrg \u00b6 1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-+(?=-)' TestOrg \u00b6 1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-\\(test-org\\)' --trim-account-name '-+(?=-)' --components test,account_name,role_name,region Alternatively, you can configure a single profile with a custom name like so: 1 aws-sso-util configure profile your-profile-name You only need to login once per every 8 hours to use all your accounts, which can be facilitated done with the following command: 1 aws-sso-util login To use different accounts you may either set the account for the current shell using export AWS_PROFILE=your-profile-name or supply the --profile your-profile-name option all your aws commands. When using zsh (e.g. MacOS), you can activate the aws plugin and then make use of the asp your-profile-name command, which also offers auto-completion. go-aws-sso \u00b6 This tool lets you interactively (or directly) select the account and role you want credentials for. It has no external dependencies and ships as a pre-built binary for your platform. You may install the tool via a homebrew tap, downloading the binary, go install or from source. After installation, just run go-aws-sso . At first time usage, you will be prompted for your SSO Start URL and your region (those values will be stored in a separate config file) * idealo start URL: https://idealo-login.awsapps.com/start#/ * idealo default region: eu-central-1 Now you can select your account and role. Prolong session durations \u00b6 If the default session duration of 1h is to short, you can prolong this duration by following this guide . Access accounts cloudtrail logs \u00b6 Cloudtrail logs contain every event that happens in your account. How to search/access that logs is described here . Management \u00b6 Moving an account to another KOMUEB \u00b6 This can't be done by just a PR. Manually work is required to accomplish this task. The reason is that the TF state files are stored in S3 and simply moving the files would cause the deletion of the corresponding account(s). To move an account to another KOMUEB just follow these steps: Set the permission from it-all to Read Disable all workflows in the repository (you can simply do that with the GitHub web ui) Log into the Organisation Management account and move in S3 the tf state file to the new location (the tf states are located in the bucket idealo-prod-org-tg-state ) Move in the repository the account file (and eventually permission sets) to the new KOMUEB folder. Create a PR and finally merge it (no action SHOULD be triggered) Re-enable all GitHub workflows again Finally, change the field komueb_product_ticket in the moved account file, create a PR and merge it as normal Set it-all back to Write again",
      "title":"AWS Accounts @ idealo"
    },
    {
      "location":"#aws-accounts-idealo",
      "text":"idealo aims to provide everyone a painless way of creating and managing your AWS accounts in our organization. This project manages all our accounts using Terraform and automated pipelines. You can access your accounts at https://idealo-login.awsapps.com/start#/ . They can also be made available in the CLI by running aws configure sso .",
      "title":"AWS Accounts @ idealo"
    },
    {
      "location":"#visualisation-of-existing-aws-accounts",
      "text":"The AWS Accounts Overview Page in Backstage provides an interactive overview for all AWS accounts we have in idealo.",
      "title":"Visualisation of existing AWS accounts"
    },
    {
      "location":"#usage",
      "text":"",
      "title":"Usage"
    },
    {
      "location":"#precondition",
      "text":"",
      "title":"Precondition"
    },
    {
      "location":"#how-to-slice-an-account",
      "text":"The idealo organisation has rules on how to slice your account. The details can be found here .",
      "title":"How to slice an account"
    },
    {
      "location":"#use-case-and-environment",
      "text":"Beforehand, you need to know for which use case and environment you want to create this account. This is important to find the related KOMUEB ticket id and to determine the correct organizational unit (OU). We differentiate between accounts which are related to a subdomain and sandbox accounts which are unrelated to a subdomain. SANDBOX: These accounts are not related to a product/subdomain. These are for playground/experimental/research purposes. Due to this, all resources in these accounts will be nuked every night automatically. These accounts are connected to the following product in the Verfahrensverzeichnis: KOMUEB-3188 - AWS Sandbox Accounts SDLC: Stands for Software Development Life Cycle. This category includes accounts for dev/testing/staging environments that are assigned to a product/sub-domain. Therefore, you need the KOMUEB ticket id of the associated product to order an account. Talk to your PO in order to find the correct ticket and let the PO create one if it's missing. PRODUCTION: This is meant for productive resources, i.e. things that are ready to use by your customers (be it internal or external).",
      "title":"Use Case and Environment"
    },
    {
      "location":"#komueb-verfahrensverzeichnis-product-overview",
      "text":"References to KOMUEB in this document can be understood as references to PDEKOM for preis.de users. The Verfahrensverzeichnis is our central product overview in Jira. All running products are listed here with related information like responsible colleague and GDPR facts (handles personal data). A KOMUEB ticket is automatically created for each AWS account and this is linked to the KOMUEB ticket for the product. A product can be linked to multiple AWS accounts KOMUEB tickets. (e.g.: account for staging and production). If you don't have a KOMUEB-Ticket for your subdomain please ask your product owner to create a suitable ticket.",
      "title":"KOMUEB / Verfahrensverzeichnis / Product overview"
    },
    {
      "location":"#access-management",
      "text":"Access to the accounts is granted using AWS SSO, which is linked to our Azure AD. That's why the setup requires existing users and user groups in our Azure AD. Please ensure that you set up groups accordingly using the GroupTool . You are free to use any preexisting user group and don't need to create a group with specific naming conventions anymore.",
      "title":"Access Management"
    },
    {
      "location":"#creating-a-new-aws-account",
      "text":"The entire account configuration is based on the aws-prod-org directory. The aws-test-org is for CST testing purposes only. Ensure that you have read the preconditions . Edit this project with your favorite editor, e.g. by cloning it. Create a branch from main with an appropriate name. The name should reflect the requesting team and product/subdomain. Copy the example folder ( examples/account/KOMUEB-xyz ) folder into aws-prod-org and rename it to match your KOMUEB ticket (issuetype product!) id (e.g. KOMUEB-1234 ). SANDBOX: If you want to create a sandbox account, which is not related to a product/subdomain, please add your account request to the KOMUEB-3188 directory in aws-prod-org . SDLC: If you want to create an SDLC account, please use the corresponding product KOMUEB ticket id as described in the preconditions . Rename the Account Name directory inside to match the account name you want to request. Edit the terragrunt.hcl file in the directory you just renamed in step 5 and fill in the inputs. For detailed explanations on the variables, please refer to the module documentation . Commit & push your changes, then open a pull request . When opening a pull request a template for the description will already be pre-filled, which you should simply fill out in the appropriate spots. After your pull request was reviewed and merged you will receive more information on the next steps. Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ .",
      "title":"Creating a New AWS Account"
    },
    {
      "location":"#updating-an-account",
      "text":"Updating can be achieved in a similar manner as creating accounts. Simply find the account configuration that you want to change, edit the variables and make a pull request out of it. Please note that renaming an account is not allowed. Moving an account to a different directory (e.g. by moving to a different KOMUEB) will require manual steps by the Engineering Experience Team to move the backing state file of the module instance. Otherwise, the workflows will attempt to create a new account, but fail due to duplicated names.",
      "title":"Updating an Account"
    },
    {
      "location":"#changing-azure-ad-group-names",
      "text":"When changing the name of an existing Azure AD group that is assigned to a permission set in your configuration, there are certain steps that must be followed: Remove the assignment completely from the configuration, commit, and merge the PR Add the assignment with the new group name, commit and merge the PR This is required, as you may receive an error message stating that the group already exists if these steps are not followed.",
      "title":"Changing Azure AD group names"
    },
    {
      "location":"#closing-an-account",
      "text":"Closing an account can be achieved by deleting its configuration from this repository via a pull request. For a detailed step-by-step guide, please visit this page .",
      "title":"Closing an Account"
    },
    {
      "location":"#using-managed-account-budgets",
      "text":"AWS accounts created with this process get a managed budget incl. alerts. Sandbox accounts default to a budget of 200 USD and non-sandbox accounts to a budget of 2000 USD. You'll get three alerts alongside your budget out-of-the-box: Your actual cost is greater than 80% of your budget Your actual cost is greater than 100% of your budget Your forecasted cost is greater than 100% of your budget You'll get automatically notified via email. You may control the amount of your budget via the account_budget property of the aws-account module. This property can be updated later on. You may control the recipient's email address of alerts for your budget via the account_budget_email property of the aws-account module. This property can be updated later on.",
      "title":"Using Managed Account Budgets"
    },
    {
      "location":"#login-to-an-account",
      "text":"Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ . This UI will provide you with access to the management console or programmatic access with temporary credentials. You may also access the account using the CLI command aws configure sso . This command requires AWS CLI v2. If you still have v1, you will need to uninstall it (having both is not really recommended as they both use the same command, aws). Info v1 (for uninstalling) https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html#install-macosos-bundled Info v2 (for installing) https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html",
      "title":"Login to an Account"
    },
    {
      "location":"#aws-account-credentials",
      "text":"There are several options to handle your account credentials for the AWS CLI. For easy CLI access you can use aws-sso-util or go-aws-sso",
      "title":"AWS Account Credentials"
    },
    {
      "location":"#sso-start-url",
      "text":"",
      "title":"SSO Start URL"
    },
    {
      "location":"#prodorg",
      "text":"1 https://idealo-login.awsapps.com/start#/",
      "title":"ProdOrg"
    },
    {
      "location":"#testorg",
      "text":"1 https://idealo-test-login.awsapps.com/start#/",
      "title":"TestOrg"
    },
    {
      "location":"#sso-region",
      "text":"",
      "title":"SSO Region"
    },
    {
      "location":"#1eu-central-1",
      "text":"",
      "title":"1eu-central-1\n"
    },
    {
      "location":"#aws-sso-util",
      "text":"After you have installed the tool, you may want to add the following environment variable definitions to your shell profile (e.g. ~/.bashrc or ~/.zshrc ) 1 2 export AWS_DEFAULT_SSO_START_URL = \"https://idealo-login.awsapps.com/start#/\" export AWS_DEFAULT_SSO_REGION = \"eu-central-1\" With that done, you can import all your SSO accounts roles like shown in the command below. This will create profile names like foo-account.admin or bar-account.readonly .",
      "title":"aws-sso-util"
    },
    {
      "location":"#prodorg_1",
      "text":"1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-+(?=-)'",
      "title":"ProdOrg"
    },
    {
      "location":"#testorg_1",
      "text":"1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-\\(test-org\\)' --trim-account-name '-+(?=-)' --components test,account_name,role_name,region Alternatively, you can configure a single profile with a custom name like so: 1 aws-sso-util configure profile your-profile-name You only need to login once per every 8 hours to use all your accounts, which can be facilitated done with the following command: 1 aws-sso-util login To use different accounts you may either set the account for the current shell using export AWS_PROFILE=your-profile-name or supply the --profile your-profile-name option all your aws commands. When using zsh (e.g. MacOS), you can activate the aws plugin and then make use of the asp your-profile-name command, which also offers auto-completion.",
      "title":"TestOrg"
    },
    {
      "location":"#go-aws-sso",
      "text":"This tool lets you interactively (or directly) select the account and role you want credentials for. It has no external dependencies and ships as a pre-built binary for your platform. You may install the tool via a homebrew tap, downloading the binary, go install or from source. After installation, just run go-aws-sso . At first time usage, you will be prompted for your SSO Start URL and your region (those values will be stored in a separate config file) * idealo start URL: https://idealo-login.awsapps.com/start#/ * idealo default region: eu-central-1 Now you can select your account and role.",
      "title":"go-aws-sso"
    },
    {
      "location":"#prolong-session-durations",
      "text":"If the default session duration of 1h is to short, you can prolong this duration by following this guide .",
      "title":"Prolong session durations"
    },
    {
      "location":"#access-accounts-cloudtrail-logs",
      "text":"Cloudtrail logs contain every event that happens in your account. How to search/access that logs is described here .",
      "title":"Access accounts cloudtrail logs"
    },
    {
      "location":"#management",
      "text":"",
      "title":"Management"
    },
    {
      "location":"#moving-an-account-to-another-komueb",
      "text":"This can't be done by just a PR. Manually work is required to accomplish this task. The reason is that the TF state files are stored in S3 and simply moving the files would cause the deletion of the corresponding account(s). To move an account to another KOMUEB just follow these steps: Set the permission from it-all to Read Disable all workflows in the repository (you can simply do that with the GitHub web ui) Log into the Organisation Management account and move in S3 the tf state file to the new location (the tf states are located in the bucket idealo-prod-org-tg-state ) Move in the repository the account file (and eventually permission sets) to the new KOMUEB folder. Create a PR and finally merge it (no action SHOULD be triggered) Re-enable all GitHub workflows again Finally, change the field komueb_product_ticket in the moved account file, create a PR and merge it as normal Set it-all back to Write again",
      "title":"Moving an account to another KOMUEB"
    },
    {
      "location":"account-closure/",
      "text":"AWS Account Closure Process \u00b6 AWS Account Closure from AWS' Perspective \u00b6 (Source: https://miro.com/app/board/o9J_lxbRomI=/ ) Additional Resources: * Closing an AWS account * Closing an AWS Organizations member account AWS Account Closure Step by Step Guide \u00b6 Delete Resources \u00b6 [!NOTE] The following tasks have to be done by the account owners team: Delete all of your resources within the account Org-managed resources (e.g. CloudTrail) will automatically be deleted later on Resources may still incur costs in certain scenarios Resources cannot be deleted/terminated during the post-closure period Cancel Subscriptions \u00b6 [!NOTE] The following tasks have to be done by the account owners team: Cancel all marketplace subscriptions within your account Subscription may still incur costs, even after closure until the end of the post-closure period and beyond Marketplace subscriptions cannot be canceled during the post-closure period Close Account \u00b6 [!NOTE] The following tasks have to be done by the account owner: Create a pull request in the aws-accounts repo, deleting the terragrunt.hcl configuration for the account you want to close The 90-day post-closure period begins after the pull request was merged Remove Account Root Email Address from Active Directory \u00b6 [!NOTE] The following tasks have to be done by the account owner: Go to https://idealo-grpmgmt-prod.azurewebsites.net/# You have to be group owner for that. Since you are account owner, this should hopefully be the case Delete the group of the root account's email address (for non idealo-org accounts make sure it's not used in another context)",
      "title":"AWS Account Closure Process"
    },
    {
      "location":"account-closure/#aws-account-closure-process",
      "text":"",
      "title":"AWS Account Closure Process"
    },
    {
      "location":"account-closure/#aws-account-closure-from-aws-perspective",
      "text":"(Source: https://miro.com/app/board/o9J_lxbRomI=/ ) Additional Resources: * Closing an AWS account * Closing an AWS Organizations member account",
      "title":"AWS Account Closure from AWS' Perspective"
    },
    {
      "location":"account-closure/#aws-account-closure-step-by-step-guide",
      "text":"",
      "title":"AWS Account Closure Step by Step Guide"
    },
    {
      "location":"account-closure/#delete-resources",
      "text":"[!NOTE] The following tasks have to be done by the account owners team: Delete all of your resources within the account Org-managed resources (e.g. CloudTrail) will automatically be deleted later on Resources may still incur costs in certain scenarios Resources cannot be deleted/terminated during the post-closure period",
      "title":"Delete Resources"
    },
    {
      "location":"account-closure/#cancel-subscriptions",
      "text":"[!NOTE] The following tasks have to be done by the account owners team: Cancel all marketplace subscriptions within your account Subscription may still incur costs, even after closure until the end of the post-closure period and beyond Marketplace subscriptions cannot be canceled during the post-closure period",
      "title":"Cancel Subscriptions"
    },
    {
      "location":"account-closure/#close-account",
      "text":"[!NOTE] The following tasks have to be done by the account owner: Create a pull request in the aws-accounts repo, deleting the terragrunt.hcl configuration for the account you want to close The 90-day post-closure period begins after the pull request was merged",
      "title":"Close Account"
    },
    {
      "location":"account-closure/#remove-account-root-email-address-from-active-directory",
      "text":"[!NOTE] The following tasks have to be done by the account owner: Go to https://idealo-grpmgmt-prod.azurewebsites.net/# You have to be group owner for that. Since you are account owner, this should hopefully be the case Delete the group of the root account's email address (for non idealo-org accounts make sure it's not used in another context)",
      "title":"Remove Account Root Email Address from Active Directory"
    },
    {
      "location":"account-slicing-guidelines/",
      "text":"AWS Account Slicing Guidelines \u00b6 Note: Workload and SDLC accounts SHOULD be sliced after subdomains only (one production account per subdomain) Each account MUST clearly be assigned to one team (no shared ownership) In some corner cases it might make sense to have multiple productive AWS accounts per Subdomain. Please talk to the Engineering Experience Team, if you see this need. Sandbox accounts may be sliced differently (e.g. per team, per individual) and SHOULD be nuked daily. Reasoning \u00b6 As described here , teams in PT are #end-to-end-responsible for one or more subdomains. These subdomains mark clear borders of responsibility: Teams are responsible for maintaining, securing and operating the implementation of their subdomain(s) in software (the system). The borders of this system must match the borders of the according subdomain. Only this way the teams can be #end-to-end-responsible for their part of the overall system. This goes hand-in-hand with the decentralised data protection mechanism we follow at idealo. The responsible team for a certain domain is responsible for protecting the data processed and stored in their subdomain. We document this by linking each subdomain to a product in the Verfahrensverzeichnis . Each product in the Verfahrensverzeichnis has a 1-to-1 relationship with the according subdomain. AWS accounts are a perfect match for these borders of responsibilities in AWS. The responsible team for the subdomain / account has everything in their hands to operate their subdomain in this AWS account. With AWS IAM the team has everything in their hands to protect processed and stored data of this subdomain and grant access to this data in a decentralised way. In the Verfahrensverzeichnis the AWS account itself is documented as a technical component of the product / subdomain. This makes it potentially possible to have multiple AWS accounts per subdomain, which come at a price and should be avoided in most cases. Implications of this decision \u00b6 AWS account slicing after subdomains is a perfect fit for our decentralised data protection approach and our guiding principles #domain-driven and #end-to-end-responsibility PA accounts or shared accounts between teams is not possible any longer If a team uses an IaC product, this product should be instantiated and kept up-to-date by the team who owns the account. These deployments and the operations should be as smooth as possible. It\u2019s also OK that a team operates an IaC product for e.g. the whole PA and gives them access as long as the shared responsibility (e.g. in terms of data protection) is clearly defined. FAQ \u00b6 Subdomains \u00b6 How do we identify our subdomains? If you struggle to find good subdomains, don\u2019t panic. Subdomains must not be perfect at first shot. If you need help defining your subdomain, you can ask the #domain-driven Guiding Principle guards ( Krister Saleck , Christoph Korn ) to help you with that. If you really do not find a good subdomain, please: At least create one account per team, but do name the account after what the team is doing and not after the team name. Do not take the current products in the Verfahrensverzeichnis as granted. First define your subdomain and derive from that what goes as product in the Verfahrensverzeichnis. What about platform subdomains? In general we differentiate between value stream aligned, complicated subsystem and platform subdomains. This account slicing proposal refers to all three of these. So to make it clear: We also see AWS accounts for centrally operated platform services. What about IaC platform products? Do they need their own AWS account then? No, we rather think that IaC products should be instantiated in the subdomain AWS accounts that use these products. Subdomain overarching concerns \u00b6 What about virtual teams/focus groups? Can they own an AWS account? As long as a PO or a HoX is accountable for this account (mentioned as accountable in the Verfahrensverzeichnis), it should be OK, that the owning team is a virtual team. However, please clarify this with Andreas Jentsch or Mike Lesniak in each case beforehand. Can we give cross-team on-call access to accounts? Every owning team can give another team or single persons access to their account. Still, the owning team remains responsible for the account as well as keeping track of access. Can a team operate their own cross-domain \u201cinfrastructure account\u201d? In rare cases, a responsible team may have an account dedicated to their cross-domain infrastructure products, if absolutely necessary. However, this is not recommended. Try to keep infrastructure required for your subdomain with your subdomain apps in the same account. Also, think about your subdomains. If multiple subdomains in your responsibility use the same things, e.g. data, these same things may indeed represent their own subdomain. Can we keep our PA account (e.g with our logging stack), as long as we have services in the DC? In the new AWS organisation we don\u2019t want to have PA accounts. As long as the account can stay in the AWS organisation of Axel Springer, we may keep it as a PA account. However, as soon as we need to move out of the Axel Springer organisation, we have to find another solution (e.g. a designated team and accountable owner in the PA). Can we keep our PA account in the new AWS organisation? No. Please find another solution, e.g. a designated (virtual) team and accountable owner in the PA that owns certain things and offers these as a service in an AWS account. Responsibilities \u00b6 Who is the person that is accountable for an AWS account? The single person that is accountable for an AWS account is the one mentioned as accountable in the Verfahrensverzeichnis for the corresponding product. This needs to be either a PO, a HoP, or a HoT. Who is the team that is owning an AWS account? The default is that ownership of AWS accounts belongs to teams as per the organisational structure. However, for some rare subdomain overarching concerns \u201cvirtual teams\u201d may also assume this role if responsibility is taken, team membership is clear, and a designated accountable person is defined. Sandbox / Playground accounts \u00b6 Do we need a KOMUEB-Ticket (sub-domain) for a sandbox/playground account? No you don\u2019t need your own KOMUEB-Ticket. All Sandbox accounts are linked to a generic sandbox ticket. Please use this one: KOMUEB-3188 Prerequisites \u00b6 What do we need for an AWS account? You need an entry in the Verfahrensverzeichnis for your subdomain. This can be a part of a business domain or an infrastructure/platform product You need an accountable person. This must be a PO or a HoT/HoP You need the cost center of your PA",
      "title":"AWS Account Slicing Guidelines"
    },
    {
      "location":"account-slicing-guidelines/#aws-account-slicing-guidelines",
      "text":"Note: Workload and SDLC accounts SHOULD be sliced after subdomains only (one production account per subdomain) Each account MUST clearly be assigned to one team (no shared ownership) In some corner cases it might make sense to have multiple productive AWS accounts per Subdomain. Please talk to the Engineering Experience Team, if you see this need. Sandbox accounts may be sliced differently (e.g. per team, per individual) and SHOULD be nuked daily.",
      "title":"AWS Account Slicing Guidelines"
    },
    {
      "location":"account-slicing-guidelines/#reasoning",
      "text":"As described here , teams in PT are #end-to-end-responsible for one or more subdomains. These subdomains mark clear borders of responsibility: Teams are responsible for maintaining, securing and operating the implementation of their subdomain(s) in software (the system). The borders of this system must match the borders of the according subdomain. Only this way the teams can be #end-to-end-responsible for their part of the overall system. This goes hand-in-hand with the decentralised data protection mechanism we follow at idealo. The responsible team for a certain domain is responsible for protecting the data processed and stored in their subdomain. We document this by linking each subdomain to a product in the Verfahrensverzeichnis . Each product in the Verfahrensverzeichnis has a 1-to-1 relationship with the according subdomain. AWS accounts are a perfect match for these borders of responsibilities in AWS. The responsible team for the subdomain / account has everything in their hands to operate their subdomain in this AWS account. With AWS IAM the team has everything in their hands to protect processed and stored data of this subdomain and grant access to this data in a decentralised way. In the Verfahrensverzeichnis the AWS account itself is documented as a technical component of the product / subdomain. This makes it potentially possible to have multiple AWS accounts per subdomain, which come at a price and should be avoided in most cases.",
      "title":"Reasoning"
    },
    {
      "location":"account-slicing-guidelines/#implications-of-this-decision",
      "text":"AWS account slicing after subdomains is a perfect fit for our decentralised data protection approach and our guiding principles #domain-driven and #end-to-end-responsibility PA accounts or shared accounts between teams is not possible any longer If a team uses an IaC product, this product should be instantiated and kept up-to-date by the team who owns the account. These deployments and the operations should be as smooth as possible. It\u2019s also OK that a team operates an IaC product for e.g. the whole PA and gives them access as long as the shared responsibility (e.g. in terms of data protection) is clearly defined.",
      "title":"Implications of this decision"
    },
    {
      "location":"account-slicing-guidelines/#faq",
      "text":"",
      "title":"FAQ"
    },
    {
      "location":"account-slicing-guidelines/#subdomains",
      "text":"How do we identify our subdomains? If you struggle to find good subdomains, don\u2019t panic. Subdomains must not be perfect at first shot. If you need help defining your subdomain, you can ask the #domain-driven Guiding Principle guards ( Krister Saleck , Christoph Korn ) to help you with that. If you really do not find a good subdomain, please: At least create one account per team, but do name the account after what the team is doing and not after the team name. Do not take the current products in the Verfahrensverzeichnis as granted. First define your subdomain and derive from that what goes as product in the Verfahrensverzeichnis. What about platform subdomains? In general we differentiate between value stream aligned, complicated subsystem and platform subdomains. This account slicing proposal refers to all three of these. So to make it clear: We also see AWS accounts for centrally operated platform services. What about IaC platform products? Do they need their own AWS account then? No, we rather think that IaC products should be instantiated in the subdomain AWS accounts that use these products.",
      "title":"Subdomains"
    },
    {
      "location":"account-slicing-guidelines/#subdomain-overarching-concerns",
      "text":"What about virtual teams/focus groups? Can they own an AWS account? As long as a PO or a HoX is accountable for this account (mentioned as accountable in the Verfahrensverzeichnis), it should be OK, that the owning team is a virtual team. However, please clarify this with Andreas Jentsch or Mike Lesniak in each case beforehand. Can we give cross-team on-call access to accounts? Every owning team can give another team or single persons access to their account. Still, the owning team remains responsible for the account as well as keeping track of access. Can a team operate their own cross-domain \u201cinfrastructure account\u201d? In rare cases, a responsible team may have an account dedicated to their cross-domain infrastructure products, if absolutely necessary. However, this is not recommended. Try to keep infrastructure required for your subdomain with your subdomain apps in the same account. Also, think about your subdomains. If multiple subdomains in your responsibility use the same things, e.g. data, these same things may indeed represent their own subdomain. Can we keep our PA account (e.g with our logging stack), as long as we have services in the DC? In the new AWS organisation we don\u2019t want to have PA accounts. As long as the account can stay in the AWS organisation of Axel Springer, we may keep it as a PA account. However, as soon as we need to move out of the Axel Springer organisation, we have to find another solution (e.g. a designated team and accountable owner in the PA). Can we keep our PA account in the new AWS organisation? No. Please find another solution, e.g. a designated (virtual) team and accountable owner in the PA that owns certain things and offers these as a service in an AWS account.",
      "title":"Subdomain overarching concerns"
    },
    {
      "location":"account-slicing-guidelines/#responsibilities",
      "text":"Who is the person that is accountable for an AWS account? The single person that is accountable for an AWS account is the one mentioned as accountable in the Verfahrensverzeichnis for the corresponding product. This needs to be either a PO, a HoP, or a HoT. Who is the team that is owning an AWS account? The default is that ownership of AWS accounts belongs to teams as per the organisational structure. However, for some rare subdomain overarching concerns \u201cvirtual teams\u201d may also assume this role if responsibility is taken, team membership is clear, and a designated accountable person is defined.",
      "title":"Responsibilities"
    },
    {
      "location":"account-slicing-guidelines/#sandbox-playground-accounts",
      "text":"Do we need a KOMUEB-Ticket (sub-domain) for a sandbox/playground account? No you don\u2019t need your own KOMUEB-Ticket. All Sandbox accounts are linked to a generic sandbox ticket. Please use this one: KOMUEB-3188",
      "title":"Sandbox / Playground accounts"
    },
    {
      "location":"account-slicing-guidelines/#prerequisites",
      "text":"What do we need for an AWS account? You need an entry in the Verfahrensverzeichnis for your subdomain. This can be a part of a business domain or an infrastructure/platform product You need an accountable person. This must be a PO or a HoT/HoP You need the cost center of your PA",
      "title":"Prerequisites"
    },
    {
      "location":"cloudtrail-logs/",
      "text":"CloudTrail logs \u00b6 Cloudtrail logs are active for every account. They log all the events which are take place and store them finally in a S3 bucket in the central log archive account. In your own account you only had access to cloudtrail itself but not to the stored logs itself. Because it could be very cumbersome to find something in cloudtrail itself, we implemented the access to your accounts cloudtrail logs via the query engine Athena. [!NOTE] You can only view logs in eu-central-1, eu-west-1 and us-east-1 regions. How a cloudtrail entry looks like \u00b6 Here is a example when a user is logging into a account. The main field names are always the same. If a event just don't have data for a specific field, it is null . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \"eventVersion\" : \"1.08\" , \"userIdentity\" : { \"type\" : \"AssumedRole\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU:john.doe@idealo.de\" , \"arn\" : \"arn:aws:sts::187437750615:assumed-role/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802/john.doe@idealo.de\" , \"accountId\" : \"187437750615\" , \"sessionContext\" : { \"sessionIssuer\" : { \"type\" : \"Role\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU\" , \"arn\" : \"arn:aws:iam::187437750615:role/aws-reserved/sso.amazonaws.com/eu-central-1/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" , \"accountId\" : \"187437750615\" , \"userName\" : \"AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" }, \"webIdFederationData\" : {}, \"attributes\" : { \"creationDate\" : \"2022-10-11T11:48:42Z\" , \"mfaAuthenticated\" : \"false\" } } }, \"eventTime\" : \"2022-10-11T11:48:43Z\" , \"eventSource\" : \"signin.amazonaws.com\" , \"eventName\" : \"ConsoleLogin\" , \"awsRegion\" : \"eu-central-1\" , \"sourceIPAddress\" : \"95.90.235.41\" , \"userAgent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\" , \"requestParameters\" : null , \"responseElements\" : { \"ConsoleLogin\" : \"Success\" }, \"additionalEventData\" : { \"MobileVersion\" : \"No\" , \"MFAUsed\" : \"No\" }, \"eventID\" : \"31d91c11-44e7-4745-99f1-49e81d3a452a\" , \"readOnly\" : false , \"eventType\" : \"AwsConsoleSignIn\" , \"managementEvent\" : true , \"recipientAccountId\" : \"187437750615\" , \"eventCategory\" : \"Management\" , \"tlsDetails\" : { \"tlsVersion\" : \"TLSv1.2\" , \"cipherSuite\" : \"ECDHE-RSA-AES128-GCM-SHA256\" , \"clientProvidedHostHeader\" : \"eu-central-1.signin.aws.amazon.com\" } } Use SELECT to find entries \u00b6 So lets take the example above and try to find that now with athena. For that just go via the console to athena and select the database cloudtrail . In that database the table of interest is logs . [!NOTE] In athena you need to specify a S3 bucket where query results should be written to. If not already done, just define that bucket under Settings in Query result location. Before we start there a some things to note: The data is partioned by days from the 2022/01/06 on and the corresponding field is named timestamp . So if you want to isolate the results more, you need to work on the field eventTime If you want to access subfields you have to work with the dot notation (will be shown in the example) Ok, lets assume you want to find the account logins from a specific user on a specific day: 1 SELECT * FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ; The result coud be unreadable for you, since every information of the whole subfields are squeezed into a single line, like userIdentity for example. To shrink the result to the informations you need/want, just define the fields of interest in the query. To see all available table fields just press in the aws athena console the + icon left from the table name (logs) or see the JSON example above. 1 SELECT eventtime , sourceipaddress FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ; Define time ranges \u00b6 Sometimes it might be helpful to define timeranges for the search in regards to days or intraday times. You can achieve that with the following syntaxes. [!NOTE] On single digit day numbers work with a leading 0 Use placeholders in dates \u00b6 1 2 WHERE timestamp like '2022/09/1%' WHERE timestamp like '2022/10/2%' Use a date range \u00b6 1 WHERE timestamp >= '2022/10/09' AND timestamp <= '2022/10/10' Use time filtering \u00b6 1 WHERE eventtime >= '2022-10-11T10:00' AND timestamp = '2022/10/11' Related links \u00b6 AWS documentation of SELECT in athena",
      "title":"CloudTrail logs"
    },
    {
      "location":"cloudtrail-logs/#cloudtrail-logs",
      "text":"Cloudtrail logs are active for every account. They log all the events which are take place and store them finally in a S3 bucket in the central log archive account. In your own account you only had access to cloudtrail itself but not to the stored logs itself. Because it could be very cumbersome to find something in cloudtrail itself, we implemented the access to your accounts cloudtrail logs via the query engine Athena. [!NOTE] You can only view logs in eu-central-1, eu-west-1 and us-east-1 regions.",
      "title":"CloudTrail logs"
    },
    {
      "location":"cloudtrail-logs/#how-a-cloudtrail-entry-looks-like",
      "text":"Here is a example when a user is logging into a account. The main field names are always the same. If a event just don't have data for a specific field, it is null . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \"eventVersion\" : \"1.08\" , \"userIdentity\" : { \"type\" : \"AssumedRole\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU:john.doe@idealo.de\" , \"arn\" : \"arn:aws:sts::187437750615:assumed-role/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802/john.doe@idealo.de\" , \"accountId\" : \"187437750615\" , \"sessionContext\" : { \"sessionIssuer\" : { \"type\" : \"Role\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU\" , \"arn\" : \"arn:aws:iam::187437750615:role/aws-reserved/sso.amazonaws.com/eu-central-1/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" , \"accountId\" : \"187437750615\" , \"userName\" : \"AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" }, \"webIdFederationData\" : {}, \"attributes\" : { \"creationDate\" : \"2022-10-11T11:48:42Z\" , \"mfaAuthenticated\" : \"false\" } } }, \"eventTime\" : \"2022-10-11T11:48:43Z\" , \"eventSource\" : \"signin.amazonaws.com\" , \"eventName\" : \"ConsoleLogin\" , \"awsRegion\" : \"eu-central-1\" , \"sourceIPAddress\" : \"95.90.235.41\" , \"userAgent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\" , \"requestParameters\" : null , \"responseElements\" : { \"ConsoleLogin\" : \"Success\" }, \"additionalEventData\" : { \"MobileVersion\" : \"No\" , \"MFAUsed\" : \"No\" }, \"eventID\" : \"31d91c11-44e7-4745-99f1-49e81d3a452a\" , \"readOnly\" : false , \"eventType\" : \"AwsConsoleSignIn\" , \"managementEvent\" : true , \"recipientAccountId\" : \"187437750615\" , \"eventCategory\" : \"Management\" , \"tlsDetails\" : { \"tlsVersion\" : \"TLSv1.2\" , \"cipherSuite\" : \"ECDHE-RSA-AES128-GCM-SHA256\" , \"clientProvidedHostHeader\" : \"eu-central-1.signin.aws.amazon.com\" } }",
      "title":"How a cloudtrail entry looks like"
    },
    {
      "location":"cloudtrail-logs/#use-select-to-find-entries",
      "text":"So lets take the example above and try to find that now with athena. For that just go via the console to athena and select the database cloudtrail . In that database the table of interest is logs . [!NOTE] In athena you need to specify a S3 bucket where query results should be written to. If not already done, just define that bucket under Settings in Query result location. Before we start there a some things to note: The data is partioned by days from the 2022/01/06 on and the corresponding field is named timestamp . So if you want to isolate the results more, you need to work on the field eventTime If you want to access subfields you have to work with the dot notation (will be shown in the example) Ok, lets assume you want to find the account logins from a specific user on a specific day: 1 SELECT * FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ; The result coud be unreadable for you, since every information of the whole subfields are squeezed into a single line, like userIdentity for example. To shrink the result to the informations you need/want, just define the fields of interest in the query. To see all available table fields just press in the aws athena console the + icon left from the table name (logs) or see the JSON example above. 1 SELECT eventtime , sourceipaddress FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ;",
      "title":"Use SELECT to find entries"
    },
    {
      "location":"cloudtrail-logs/#define-time-ranges",
      "text":"Sometimes it might be helpful to define timeranges for the search in regards to days or intraday times. You can achieve that with the following syntaxes. [!NOTE] On single digit day numbers work with a leading 0",
      "title":"Define time ranges"
    },
    {
      "location":"cloudtrail-logs/#use-placeholders-in-dates",
      "text":"1 2 WHERE timestamp like '2022/09/1%' WHERE timestamp like '2022/10/2%'",
      "title":"Use placeholders in dates"
    },
    {
      "location":"cloudtrail-logs/#use-a-date-range",
      "text":"1 WHERE timestamp >= '2022/10/09' AND timestamp <= '2022/10/10'",
      "title":"Use a date range"
    },
    {
      "location":"cloudtrail-logs/#use-time-filtering",
      "text":"1 WHERE eventtime >= '2022-10-11T10:00' AND timestamp = '2022/10/11'",
      "title":"Use time filtering"
    },
    {
      "location":"cloudtrail-logs/#related-links",
      "text":"AWS documentation of SELECT in athena",
      "title":"Related links"
    },
    {
      "location":"local-development/",
      "text":"Local development \u00b6 This documentation is only for the owners and maintainers of the aws organization. Local execution \u00b6 To plan and/or apply changes locally you need to expose the following key/values that are needed to execute the IaC: 1 2 3 4 5 6 7 export JIRA_PAT_TOKEN= export JIRA_CUSTOM_AUTH_HEADER_KEY= export JIRA_CUSTOM_AUTH_HEADER_VALUE= export GROUP_CREATOR_KEY= export MS_CLIENT_ID= export MS_CLIENT_SECRET= export MS_ROBOT_PASSWORD= Some values can be found in 1Password. The entry aws-accounts env variables for prod-org contains the complete list of key/values.",
      "title":"Local development"
    },
    {
      "location":"local-development/#local-development",
      "text":"This documentation is only for the owners and maintainers of the aws organization.",
      "title":"Local development"
    },
    {
      "location":"local-development/#local-execution",
      "text":"To plan and/or apply changes locally you need to expose the following key/values that are needed to execute the IaC: 1 2 3 4 5 6 7 export JIRA_PAT_TOKEN= export JIRA_CUSTOM_AUTH_HEADER_KEY= export JIRA_CUSTOM_AUTH_HEADER_VALUE= export GROUP_CREATOR_KEY= export MS_CLIENT_ID= export MS_CLIENT_SECRET= export MS_ROBOT_PASSWORD= Some values can be found in 1Password. The entry aws-accounts env variables for prod-org contains the complete list of key/values.",
      "title":"Local execution"
    },
    {
      "location":"nuking-sandbox-accounts/",
      "text":"Sandbox Account Nuking \ud83d\udca5 \u00b6 Sandbox accounts in our AWS organization will automatically delete all non-essential resources within themselves every night. This is achieved using rebuy-de/aws-nuke . If you have resources in the account that you would like to persist you may exclude them by providing your own filter config. Filtering Resources \ud83e\udea3 \u00b6 Observe the resources that are deleted and their names in the logs of the NukeProject runs in CodeBuild Write your own config to exclude the objects that you'd like to keep ( config reference ), for example: 1 2 3 4 5 accounts : REPLACE-WITH-YOUR-ACCOUNT-ID : filters : S3Bucket : - my-favorite-bucket If you want to exclude you whole account from nuking you can use the following configuration: 1 2 account-blocklist : - \"REPLACE-WITH-YOUR-ACCOUNT-ID\" Upload this into the -nuke-configs S3 bucket in your sandbox account. The file needs to end in .yml to be considered. Any changes to the existing DO-NOT-EDIT-managed-config.yml will be overridden, so make sure to create your own additional file: You can test your config by manually triggering a nuke run in CodeBuild [!NOTE] You can also specify and override other config options of aws-nuke - all .yml files in the bucket are merged together to one config. Arrays will be appended to each other during merging Temporarly Disabling AWS Nuke \ud83d\udeaf \u00b6 If you like to temporarly disable nuking due to testing purposes, you may do so in the AWS Console. Go to your AWS Console EventBridge Rules StackSet-AccountNuking[...] Disable Done \u2611\ufe0f Please be aware, that you will get every morning a warning e-Mail, stating that your nuke is not running as expected.",
      "title":"Sandbox Account Nuking \ud83d\udca5"
    },
    {
      "location":"nuking-sandbox-accounts/#sandbox-account-nuking",
      "text":"Sandbox accounts in our AWS organization will automatically delete all non-essential resources within themselves every night. This is achieved using rebuy-de/aws-nuke . If you have resources in the account that you would like to persist you may exclude them by providing your own filter config.",
      "title":"Sandbox Account Nuking \ud83d\udca5"
    },
    {
      "location":"nuking-sandbox-accounts/#filtering-resources",
      "text":"Observe the resources that are deleted and their names in the logs of the NukeProject runs in CodeBuild Write your own config to exclude the objects that you'd like to keep ( config reference ), for example: 1 2 3 4 5 accounts : REPLACE-WITH-YOUR-ACCOUNT-ID : filters : S3Bucket : - my-favorite-bucket If you want to exclude you whole account from nuking you can use the following configuration: 1 2 account-blocklist : - \"REPLACE-WITH-YOUR-ACCOUNT-ID\" Upload this into the -nuke-configs S3 bucket in your sandbox account. The file needs to end in .yml to be considered. Any changes to the existing DO-NOT-EDIT-managed-config.yml will be overridden, so make sure to create your own additional file: You can test your config by manually triggering a nuke run in CodeBuild [!NOTE] You can also specify and override other config options of aws-nuke - all .yml files in the bucket are merged together to one config. Arrays will be appended to each other during merging",
      "title":"Filtering Resources \ud83e\udea3"
    },
    {
      "location":"nuking-sandbox-accounts/#temporarly-disabling-aws-nuke",
      "text":"If you like to temporarly disable nuking due to testing purposes, you may do so in the AWS Console. Go to your AWS Console EventBridge Rules StackSet-AccountNuking[...] Disable Done \u2611\ufe0f Please be aware, that you will get every morning a warning e-Mail, stating that your nuke is not running as expected.",
      "title":"Temporarly Disabling AWS Nuke \ud83d\udeaf"
    },
    {
      "location":"prolong-session-duration/",
      "text":"How to prolong the session duration \u00b6 Preface \u00b6 Per default every permissionset comes with a default session duration of 1 hour. In most use cases this is enough, but in some other it is not. Therefore you have the possibility to prolong the session duration to 8 hours. The following sections shows you 2 way how to do that. Preconditions \u00b6 First you need to make sure that a corresponding risk ticket for the prolongation of the session duration to 8h is in place: 1. For non-prod accounts (sandbox & SDLC) there is no need to create a risk ticket as you can use the following already accepted one RISK-111129 2. For prod accounts you need to create one (You can take this ticket as a template, but don't forget to alter non-production to production there, since it was initially meant for non-production accounts). Further this ticket needs to be accepted by your PO, TL or HoX and the status must be set to RISK ACCEPTED . Afterwards the security team will review the ticket and set the status to RISK ACCEPTANCE APPROVED If point 1. is complete you have to make a pull request to this repository on github using one of the described solutions from the next chapter and put the link of the corresponding risk ticket into that PR Option 1: Use a predefined permission set \u00b6 The EXT prepared for the 3 most used permission sets ( AWSAdministratorAccess , AWSReadOnlyAccess and AWSPowerUserAccess ) an alternative with a session duration of 8h. For using this just change the option group_permissions in the corresponding terragrunt.hcl accordingly and replace the occurence of the 3 mentioned permission sets with either one of the following: AWSAdministratorAccess8h AWSReadOnlyAccess8h AWSPowerUserAccess8h Example: 1 2 3 4 5 group_permissions = { \"MyADGroup1\" = [\"AWSAdministratorAccess8h\"] \"MyADGroup2\" = [\"AWSReadOnlyAccess8h\"] \"MyADGroup3\" = [\"AWSPowerUserAccess8h\"] } Option 2: Write your own or extend your existing permission set \u00b6 Beside the predefined permission sets you have the option to write your own permission sets. Some of you already made use of that. A example of a account definition with a self defined permission set can be found here . Just make use of session_duration in the terragrunt.hcl file in the corresponding permission set folder and set the value to PT8H : 1 2 3 inputs = { session_duration = \"PT8H\" ... [!NOTE] Please be aware that only the values PT1H or PT8H are allowed. If the option is missing, PT1H is the default.",
      "title":"How to prolong the session duration"
    },
    {
      "location":"prolong-session-duration/#how-to-prolong-the-session-duration",
      "text":"",
      "title":"How to prolong the session duration"
    },
    {
      "location":"prolong-session-duration/#preface",
      "text":"Per default every permissionset comes with a default session duration of 1 hour. In most use cases this is enough, but in some other it is not. Therefore you have the possibility to prolong the session duration to 8 hours. The following sections shows you 2 way how to do that.",
      "title":"Preface"
    },
    {
      "location":"prolong-session-duration/#preconditions",
      "text":"First you need to make sure that a corresponding risk ticket for the prolongation of the session duration to 8h is in place: 1. For non-prod accounts (sandbox & SDLC) there is no need to create a risk ticket as you can use the following already accepted one RISK-111129 2. For prod accounts you need to create one (You can take this ticket as a template, but don't forget to alter non-production to production there, since it was initially meant for non-production accounts). Further this ticket needs to be accepted by your PO, TL or HoX and the status must be set to RISK ACCEPTED . Afterwards the security team will review the ticket and set the status to RISK ACCEPTANCE APPROVED If point 1. is complete you have to make a pull request to this repository on github using one of the described solutions from the next chapter and put the link of the corresponding risk ticket into that PR",
      "title":"Preconditions"
    },
    {
      "location":"prolong-session-duration/#option-1-use-a-predefined-permission-set",
      "text":"The EXT prepared for the 3 most used permission sets ( AWSAdministratorAccess , AWSReadOnlyAccess and AWSPowerUserAccess ) an alternative with a session duration of 8h. For using this just change the option group_permissions in the corresponding terragrunt.hcl accordingly and replace the occurence of the 3 mentioned permission sets with either one of the following: AWSAdministratorAccess8h AWSReadOnlyAccess8h AWSPowerUserAccess8h Example: 1 2 3 4 5 group_permissions = { \"MyADGroup1\" = [\"AWSAdministratorAccess8h\"] \"MyADGroup2\" = [\"AWSReadOnlyAccess8h\"] \"MyADGroup3\" = [\"AWSPowerUserAccess8h\"] }",
      "title":"Option 1: Use a predefined permission set"
    },
    {
      "location":"prolong-session-duration/#option-2-write-your-own-or-extend-your-existing-permission-set",
      "text":"Beside the predefined permission sets you have the option to write your own permission sets. Some of you already made use of that. A example of a account definition with a self defined permission set can be found here . Just make use of session_duration in the terragrunt.hcl file in the corresponding permission set folder and set the value to PT8H : 1 2 3 inputs = { session_duration = \"PT8H\" ... [!NOTE] Please be aware that only the values PT1H or PT8H are allowed. If the option is missing, PT1H is the default.",
      "title":"Option 2: Write your own or extend your existing permission set"
    },
    {
      "location":"renaming-aws-account/",
      "text":"Renaming AWS Account \u00b6 This page is supposed to serve as a quick guide for the steps required when renaming an AWS account managed by Control Tower in the idealo org. The procedure is rather involved. That's why you should consider closing an account and creating a new one over renaming it . However, if you still want to rename an account, follow the steps below. Disable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Create a new group for the new account email address in the GroupTool . - The email should be the account name with all spaces and special characters replaced by a minus (-), prefixed by aws. (example: aws.my-account@idealo.de ) - Owners should follow the process of enabling external emails and following the inbox like required for new accounts. Login to the AWS account with root user credentials. - If no credentials have been set for the account they should use the \"Forgot Password\" process. - Make sure that receiving external emails is allowed for the old account email group (aws.account-name). Navigate to \"Account\" from the top right dropdown menu (where it says the account name). Click on \"Edit\" in the Account Settings section. In the resulting form, update both name and email, then save. - The name should be less than 30 characters long. (example: My Account) - The email needs to match the previously created group exactly. Log out of the AWS account. Re-enable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Terminate the AWS Service Catalog Provisioned Product for the account (name with special chars and spaces replaced by underscores, e.g. Account_Name). - This will not close the account - it will just un-manage it in Control Tower and move it outside the OU. Once this is done, go to AWS Organizations and move the account into the Transitional OU (so that the AWSControlTowerExecution role is re-created via StackSet). This is important! Ensure the role was indeed re-created. Switch into the account and make sure all resources have been cleaned up. - No CloudFormation stacks from our org StackSets are left in progress or in DELETE_FAILED state in all 3 regions (eu-central-1, eu-west-1, us-east-1). 1 2 3 4 5 * This implies that you will be deleting VPCs deployed via Stack Sets. * This will also imply that you have to delete manually the s3 buckets created by the Stack Sets. * DNSZone StackSet: You may be required to temporarily re-enable the KMS CMK in us-east-1 to be able to disable Route53 Dnssec. Remember to schedule deletion again afterwards. - CloudWatch Logs Log Group \"/aws/lambda/aws-controltower-NotificationForwarder\" needs to be deleted in all 3 regions. Update the idealo/aws-accounts repository in a branch, changing the name of the account in the inputs and renaming its directory. - In case that the account has the root_email input defined, you can remove this input. Move the state file in the \"idealo-prod-org-tg-state\" S3 bucket in the Organization Management account to the correct new location. Drop the DynamoDB item for the old state path in the lock table \"idealo-prod-org-tg-lock\" . Submit PR to the idealo/aws-accounts repository with your changes and verify that the plans are correct. - It will detect a destroy of the old path - but that is fine as long as within the destroy plan you do not see any actual actions! - It is ok if the plan says it's about to create a new account though. In fact, it will not create it but rather move from the Transitional OU into the correct OU. - Make sure that none of the plans contain an account destroy! Merge the PR, let the workflows run and keep an eye on them. - Afterwards, you may want to double check if all stacks came up properly in the account via the AWSControlTowerExecution role.",
      "title":"Renaming AWS Account"
    },
    {
      "location":"renaming-aws-account/#renaming-aws-account",
      "text":"This page is supposed to serve as a quick guide for the steps required when renaming an AWS account managed by Control Tower in the idealo org. The procedure is rather involved. That's why you should consider closing an account and creating a new one over renaming it . However, if you still want to rename an account, follow the steps below. Disable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Create a new group for the new account email address in the GroupTool . - The email should be the account name with all spaces and special characters replaced by a minus (-), prefixed by aws. (example: aws.my-account@idealo.de ) - Owners should follow the process of enabling external emails and following the inbox like required for new accounts. Login to the AWS account with root user credentials. - If no credentials have been set for the account they should use the \"Forgot Password\" process. - Make sure that receiving external emails is allowed for the old account email group (aws.account-name). Navigate to \"Account\" from the top right dropdown menu (where it says the account name). Click on \"Edit\" in the Account Settings section. In the resulting form, update both name and email, then save. - The name should be less than 30 characters long. (example: My Account) - The email needs to match the previously created group exactly. Log out of the AWS account. Re-enable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Terminate the AWS Service Catalog Provisioned Product for the account (name with special chars and spaces replaced by underscores, e.g. Account_Name). - This will not close the account - it will just un-manage it in Control Tower and move it outside the OU. Once this is done, go to AWS Organizations and move the account into the Transitional OU (so that the AWSControlTowerExecution role is re-created via StackSet). This is important! Ensure the role was indeed re-created. Switch into the account and make sure all resources have been cleaned up. - No CloudFormation stacks from our org StackSets are left in progress or in DELETE_FAILED state in all 3 regions (eu-central-1, eu-west-1, us-east-1). 1 2 3 4 5 * This implies that you will be deleting VPCs deployed via Stack Sets. * This will also imply that you have to delete manually the s3 buckets created by the Stack Sets. * DNSZone StackSet: You may be required to temporarily re-enable the KMS CMK in us-east-1 to be able to disable Route53 Dnssec. Remember to schedule deletion again afterwards. - CloudWatch Logs Log Group \"/aws/lambda/aws-controltower-NotificationForwarder\" needs to be deleted in all 3 regions. Update the idealo/aws-accounts repository in a branch, changing the name of the account in the inputs and renaming its directory. - In case that the account has the root_email input defined, you can remove this input. Move the state file in the \"idealo-prod-org-tg-state\" S3 bucket in the Organization Management account to the correct new location. Drop the DynamoDB item for the old state path in the lock table \"idealo-prod-org-tg-lock\" . Submit PR to the idealo/aws-accounts repository with your changes and verify that the plans are correct. - It will detect a destroy of the old path - but that is fine as long as within the destroy plan you do not see any actual actions! - It is ok if the plan says it's about to create a new account though. In fact, it will not create it but rather move from the Transitional OU into the correct OU. - Make sure that none of the plans contain an account destroy! Merge the PR, let the workflows run and keep an eye on them. - Afterwards, you may want to double check if all stacks came up properly in the account via the AWSControlTowerExecution role.",
      "title":"Renaming AWS Account"
    }
  ]
}