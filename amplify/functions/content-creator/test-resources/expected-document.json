{"text":"\n    AWS Accounts @ idealo\n\n    Backstage link: [AWS Accounts @ idealo](https://backstage-stg.idealo.tools/document-1234/)\n\n    AWS Accounts @ idealo ¶ idealo aims to provide everyone a painless way of creating and managing your AWS accounts in our organization. This project manages all our accounts using Terraform and automated pipelines. You can access your accounts at https://idealo-login.awsapps.com/start#/ . They can also be made available in the CLI by running aws configure sso . Visualisation of existing AWS accounts ¶ The AWS Accounts Overview Page in Backstage provides an interactive overview for all AWS accounts we have in idealo. Usage ¶ Precondition ¶ How to slice an account ¶ The idealo organisation has rules on how to slice your account. The details can be found here . Use Case and Environment ¶ Beforehand, you need to know for which use case and environment you want to create this account. This is important to find the related KOMUEB ticket id and to determine the correct organizational unit (OU). We differentiate between accounts which are related to a subdomain and sandbox accounts which are unrelated to a subdomain. SANDBOX: These accounts are not related to a product/subdomain. These are for playground/experimental/research purposes. Due to this, all resources in these accounts will be nuked every night automatically. These accounts are connected to the following product in the Verfahrensverzeichnis: KOMUEB-3188 - AWS Sandbox Accounts SDLC: Stands for Software Development Life Cycle. This category includes accounts for dev/testing/staging environments that are assigned to a product/sub-domain. Therefore, you need the KOMUEB ticket id of the associated product to order an account. Talk to your PO in order to find the correct ticket and let the PO create one if it's missing. PRODUCTION: This is meant for productive resources, i.e. things that are ready to use by your customers (be it internal or external). KOMUEB / Verfahrensverzeichnis / Product overview ¶ References to KOMUEB in this document can be understood as references to PDEKOM for preis.de users. The Verfahrensverzeichnis is our central product overview in Jira. All running products are listed here with related information like responsible colleague and GDPR facts (handles personal data). A KOMUEB ticket is automatically created for each AWS account and this is linked to the KOMUEB ticket for the product. A product can be linked to multiple AWS accounts KOMUEB tickets. (e.g.: account for staging and production). If you don't have a KOMUEB-Ticket for your subdomain please ask your product owner to create a suitable ticket. Access Management ¶ Access to the accounts is granted using AWS SSO, which is linked to our Azure AD. That's why the setup requires existing users and user groups in our Azure AD. Please ensure that you set up groups accordingly using the GroupTool . You are free to use any preexisting user group and don't need to create a group with specific naming conventions anymore. Creating a New AWS Account ¶ The entire account configuration is based on the aws-prod-org directory. The aws-test-org is for CST testing purposes only. Ensure that you have read the preconditions . Edit this project with your favorite editor, e.g. by cloning it. Create a branch from main with an appropriate name. The name should reflect the requesting team and product/subdomain. Copy the example folder ( examples/account/KOMUEB-xyz ) folder into aws-prod-org and rename it to match your KOMUEB ticket (issuetype product!) id (e.g. KOMUEB-1234 ). SANDBOX: If you want to create a sandbox account, which is not related to a product/subdomain, please add your account request to the KOMUEB-3188 directory in aws-prod-org . SDLC: If you want to create an SDLC account, please use the corresponding product KOMUEB ticket id as described in the preconditions . Rename the Account Name directory inside to match the account name you want to request. Edit the terragrunt.hcl file in the directory you just renamed in step 5 and fill in the inputs. For detailed explanations on the variables, please refer to the module documentation . Commit & push your changes, then open a pull request . When opening a pull request a template for the description will already be pre-filled, which you should simply fill out in the appropriate spots. After your pull request was reviewed and merged you will receive more information on the next steps. Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ . Updating an Account ¶ Updating can be achieved in a similar manner as creating accounts. Simply find the account configuration that you want to change, edit the variables and make a pull request out of it. Please note that renaming an account is not allowed. Moving an account to a different directory (e.g. by moving to a different KOMUEB) will require manual steps by the Engineering Experience Team to move the backing state file of the module instance. Otherwise, the workflows will attempt to create a new account, but fail due to duplicated names. Changing Azure AD group names ¶ When changing the name of an existing Azure AD group that is assigned to a permission set in your configuration, there are certain steps that must be followed: Remove the assignment completely from the configuration, commit, and merge the PR Add the assignment with the new group name, commit and merge the PR This is required, as you may receive an error message stating that the group already exists if these steps are not followed. Closing an Account ¶ Closing an account can be achieved by deleting its configuration from this repository via a pull request. For a detailed step-by-step guide, please visit this page . Using Managed Account Budgets ¶ AWS accounts created with this process get a managed budget incl. alerts. Sandbox accounts default to a budget of 200 USD and non-sandbox accounts to a budget of 2000 USD. You'll get three alerts alongside your budget out-of-the-box: Your actual cost is greater than 80% of your budget Your actual cost is greater than 100% of your budget Your forecasted cost is greater than 100% of your budget You'll get automatically notified via email. You may control the amount of your budget via the account_budget property of the aws-account module. This property can be updated later on. You may control the recipient's email address of alerts for your budget via the account_budget_email property of the aws-account module. This property can be updated later on. Login to an Account ¶ Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ . This UI will provide you with access to the management console or programmatic access with temporary credentials. You may also access the account using the CLI command aws configure sso . This command requires AWS CLI v2. If you still have v1, you will need to uninstall it (having both is not really recommended as they both use the same command, aws). Info v1 (for uninstalling) https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html#install-macosos-bundled Info v2 (for installing) https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html AWS Account Credentials ¶ There are several options to handle your account credentials for the AWS CLI. For easy CLI access you can use aws-sso-util or go-aws-sso SSO Start URL ¶ ProdOrg ¶ 1 https://idealo-login.awsapps.com/start#/ TestOrg ¶ 1 https://idealo-test-login.awsapps.com/start#/ SSO Region ¶ 1 eu-central-1 ¶ aws-sso-util ¶ After you have installed the tool, you may want to add the following environment variable definitions to your shell profile (e.g. ~/.bashrc or ~/.zshrc ) 1 2 export AWS_DEFAULT_SSO_START_URL = \"https://idealo-login.awsapps.com/start#/\" export AWS_DEFAULT_SSO_REGION = \"eu-central-1\" With that done, you can import all your SSO accounts roles like shown in the command below. This will create profile names like foo-account.admin or bar-account.readonly . ProdOrg ¶ 1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-+(?=-)' TestOrg ¶ 1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-\\(test-org\\)' --trim-account-name '-+(?=-)' --components test,account_name,role_name,region Alternatively, you can configure a single profile with a custom name like so: 1 aws-sso-util configure profile your-profile-name You only need to login once per every 8 hours to use all your accounts, which can be facilitated done with the following command: 1 aws-sso-util login To use different accounts you may either set the account for the current shell using export AWS_PROFILE=your-profile-name or supply the --profile your-profile-name option all your aws commands. When using zsh (e.g. MacOS), you can activate the aws plugin and then make use of the asp your-profile-name command, which also offers auto-completion. go-aws-sso ¶ This tool lets you interactively (or directly) select the account and role you want credentials for. It has no external dependencies and ships as a pre-built binary for your platform. You may install the tool via a homebrew tap, downloading the binary, go install or from source. After installation, just run go-aws-sso . At first time usage, you will be prompted for your SSO Start URL and your region (those values will be stored in a separate config file) * idealo start URL: https://idealo-login.awsapps.com/start#/ * idealo default region: eu-central-1 Now you can select your account and role. Prolong session durations ¶ If the default session duration of 1h is to short, you can prolong this duration by following this guide . Access accounts cloudtrail logs ¶ Cloudtrail logs contain every event that happens in your account. How to search/access that logs is described here . Management ¶ Moving an account to another KOMUEB ¶ This can't be done by just a PR. Manually work is required to accomplish this task. The reason is that the TF state files are stored in S3 and simply moving the files would cause the deletion of the corresponding account(s). To move an account to another KOMUEB just follow these steps: Set the permission from it-all to Read Disable all workflows in the repository (you can simply do that with the GitHub web ui) Log into the Organisation Management account and move in S3 the tf state file to the new location (the tf states are located in the bucket idealo-prod-org-tg-state ) Move in the repository the account file (and eventually permission sets) to the new KOMUEB folder. Create a PR and finally merge it (no action SHOULD be triggered) Re-enable all GitHub workflows again Finally, change the field komueb_product_ticket in the moved account file, create a PR and merge it as normal Set it-all back to Write again\n    \n    AWS Accounts @ idealo\n\n    Backstage link: [AWS Accounts @ idealo](https://backstage-stg.idealo.tools/document-1234/#aws-accounts-idealo)\n\n    idealo aims to provide everyone a painless way of creating and managing your AWS accounts in our organization. This project manages all our accounts using Terraform and automated pipelines. You can access your accounts at https://idealo-login.awsapps.com/start#/ . They can also be made available in the CLI by running aws configure sso .\n    \n    Visualisation of existing AWS accounts\n\n    Backstage link: [Visualisation of existing AWS accounts](https://backstage-stg.idealo.tools/document-1234/#visualisation-of-existing-aws-accounts)\n\n    The AWS Accounts Overview Page in Backstage provides an interactive overview for all AWS accounts we have in idealo.\n    \n    Usage\n    \n    Precondition\n    \n    How to slice an account\n\n    Backstage link: [How to slice an account](https://backstage-stg.idealo.tools/document-1234/#how-to-slice-an-account)\n\n    The idealo organisation has rules on how to slice your account. The details can be found here .\n    \n    Use Case and Environment\n\n    Backstage link: [Use Case and Environment](https://backstage-stg.idealo.tools/document-1234/#use-case-and-environment)\n\n    Beforehand, you need to know for which use case and environment you want to create this account. This is important to find the related KOMUEB ticket id and to determine the correct organizational unit (OU). We differentiate between accounts which are related to a subdomain and sandbox accounts which are unrelated to a subdomain. SANDBOX: These accounts are not related to a product/subdomain. These are for playground/experimental/research purposes. Due to this, all resources in these accounts will be nuked every night automatically. These accounts are connected to the following product in the Verfahrensverzeichnis: KOMUEB-3188 - AWS Sandbox Accounts SDLC: Stands for Software Development Life Cycle. This category includes accounts for dev/testing/staging environments that are assigned to a product/sub-domain. Therefore, you need the KOMUEB ticket id of the associated product to order an account. Talk to your PO in order to find the correct ticket and let the PO create one if it's missing. PRODUCTION: This is meant for productive resources, i.e. things that are ready to use by your customers (be it internal or external).\n    \n    KOMUEB / Verfahrensverzeichnis / Product overview\n\n    Backstage link: [KOMUEB / Verfahrensverzeichnis / Product overview](https://backstage-stg.idealo.tools/document-1234/#komueb-verfahrensverzeichnis-product-overview)\n\n    References to KOMUEB in this document can be understood as references to PDEKOM for preis.de users. The Verfahrensverzeichnis is our central product overview in Jira. All running products are listed here with related information like responsible colleague and GDPR facts (handles personal data). A KOMUEB ticket is automatically created for each AWS account and this is linked to the KOMUEB ticket for the product. A product can be linked to multiple AWS accounts KOMUEB tickets. (e.g.: account for staging and production). If you don't have a KOMUEB-Ticket for your subdomain please ask your product owner to create a suitable ticket.\n    \n    Access Management\n\n    Backstage link: [Access Management](https://backstage-stg.idealo.tools/document-1234/#access-management)\n\n    Access to the accounts is granted using AWS SSO, which is linked to our Azure AD. That's why the setup requires existing users and user groups in our Azure AD. Please ensure that you set up groups accordingly using the GroupTool . You are free to use any preexisting user group and don't need to create a group with specific naming conventions anymore.\n    \n    Creating a New AWS Account\n\n    Backstage link: [Creating a New AWS Account](https://backstage-stg.idealo.tools/document-1234/#creating-a-new-aws-account)\n\n    The entire account configuration is based on the aws-prod-org directory. The aws-test-org is for CST testing purposes only. Ensure that you have read the preconditions . Edit this project with your favorite editor, e.g. by cloning it. Create a branch from main with an appropriate name. The name should reflect the requesting team and product/subdomain. Copy the example folder ( examples/account/KOMUEB-xyz ) folder into aws-prod-org and rename it to match your KOMUEB ticket (issuetype product!) id (e.g. KOMUEB-1234 ). SANDBOX: If you want to create a sandbox account, which is not related to a product/subdomain, please add your account request to the KOMUEB-3188 directory in aws-prod-org . SDLC: If you want to create an SDLC account, please use the corresponding product KOMUEB ticket id as described in the preconditions . Rename the Account Name directory inside to match the account name you want to request. Edit the terragrunt.hcl file in the directory you just renamed in step 5 and fill in the inputs. For detailed explanations on the variables, please refer to the module documentation . Commit & push your changes, then open a pull request . When opening a pull request a template for the description will already be pre-filled, which you should simply fill out in the appropriate spots. After your pull request was reviewed and merged you will receive more information on the next steps. Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ .\n    \n    Updating an Account\n\n    Backstage link: [Updating an Account](https://backstage-stg.idealo.tools/document-1234/#updating-an-account)\n\n    Updating can be achieved in a similar manner as creating accounts. Simply find the account configuration that you want to change, edit the variables and make a pull request out of it. Please note that renaming an account is not allowed. Moving an account to a different directory (e.g. by moving to a different KOMUEB) will require manual steps by the Engineering Experience Team to move the backing state file of the module instance. Otherwise, the workflows will attempt to create a new account, but fail due to duplicated names.\n    \n    Changing Azure AD group names\n\n    Backstage link: [Changing Azure AD group names](https://backstage-stg.idealo.tools/document-1234/#changing-azure-ad-group-names)\n\n    When changing the name of an existing Azure AD group that is assigned to a permission set in your configuration, there are certain steps that must be followed: Remove the assignment completely from the configuration, commit, and merge the PR Add the assignment with the new group name, commit and merge the PR This is required, as you may receive an error message stating that the group already exists if these steps are not followed.\n    \n    Closing an Account\n\n    Backstage link: [Closing an Account](https://backstage-stg.idealo.tools/document-1234/#closing-an-account)\n\n    Closing an account can be achieved by deleting its configuration from this repository via a pull request. For a detailed step-by-step guide, please visit this page .\n    \n    Using Managed Account Budgets\n\n    Backstage link: [Using Managed Account Budgets](https://backstage-stg.idealo.tools/document-1234/#using-managed-account-budgets)\n\n    AWS accounts created with this process get a managed budget incl. alerts. Sandbox accounts default to a budget of 200 USD and non-sandbox accounts to a budget of 2000 USD. You'll get three alerts alongside your budget out-of-the-box: Your actual cost is greater than 80% of your budget Your actual cost is greater than 100% of your budget Your forecasted cost is greater than 100% of your budget You'll get automatically notified via email. You may control the amount of your budget via the account_budget property of the aws-account module. This property can be updated later on. You may control the recipient's email address of alerts for your budget via the account_budget_email property of the aws-account module. This property can be updated later on.\n    \n    Login to an Account\n\n    Backstage link: [Login to an Account](https://backstage-stg.idealo.tools/document-1234/#login-to-an-account)\n\n    Once the account creation has finished successfully you will be able to access your new account at https://idealo-login.awsapps.com/start#/ . This UI will provide you with access to the management console or programmatic access with temporary credentials. You may also access the account using the CLI command aws configure sso . This command requires AWS CLI v2. If you still have v1, you will need to uninstall it (having both is not really recommended as they both use the same command, aws). Info v1 (for uninstalling) https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html#install-macosos-bundled Info v2 (for installing) https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html\n    \n    AWS Account Credentials\n\n    Backstage link: [AWS Account Credentials](https://backstage-stg.idealo.tools/document-1234/#aws-account-credentials)\n\n    There are several options to handle your account credentials for the AWS CLI. For easy CLI access you can use aws-sso-util or go-aws-sso\n    \n    SSO Start URL\n    \n    ProdOrg\n\n    Backstage link: [ProdOrg](https://backstage-stg.idealo.tools/document-1234/#prodorg)\n\n    1 https://idealo-login.awsapps.com/start#/\n    \n    TestOrg\n\n    Backstage link: [TestOrg](https://backstage-stg.idealo.tools/document-1234/#testorg)\n\n    1 https://idealo-test-login.awsapps.com/start#/\n    \n    SSO Region\n    \n    1eu-central-1\n\n    \n    aws-sso-util\n\n    Backstage link: [aws-sso-util](https://backstage-stg.idealo.tools/document-1234/#aws-sso-util)\n\n    After you have installed the tool, you may want to add the following environment variable definitions to your shell profile (e.g. ~/.bashrc or ~/.zshrc ) 1 2 export AWS_DEFAULT_SSO_START_URL = \"https://idealo-login.awsapps.com/start#/\" export AWS_DEFAULT_SSO_REGION = \"eu-central-1\" With that done, you can import all your SSO accounts roles like shown in the command below. This will create profile names like foo-account.admin or bar-account.readonly .\n    \n    ProdOrg\n\n    Backstage link: [ProdOrg](https://backstage-stg.idealo.tools/document-1234/#prodorg_1)\n\n    1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-+(?=-)'\n    \n    TestOrg\n\n    Backstage link: [TestOrg](https://backstage-stg.idealo.tools/document-1234/#testorg_1)\n\n    1 aws-sso-util configure populate -r eu-central-1 --account-name-case lower --role-name-case lower --trim-role-name '^aws' --trim-role-name 'access$' --trim-role-name 'access8h$' --trim-role-name '(?<=admin)istrator' --trim-account-name '-\\(test-org\\)' --trim-account-name '-+(?=-)' --components test,account_name,role_name,region Alternatively, you can configure a single profile with a custom name like so: 1 aws-sso-util configure profile your-profile-name You only need to login once per every 8 hours to use all your accounts, which can be facilitated done with the following command: 1 aws-sso-util login To use different accounts you may either set the account for the current shell using export AWS_PROFILE=your-profile-name or supply the --profile your-profile-name option all your aws commands. When using zsh (e.g. MacOS), you can activate the aws plugin and then make use of the asp your-profile-name command, which also offers auto-completion.\n    \n    go-aws-sso\n\n    Backstage link: [go-aws-sso](https://backstage-stg.idealo.tools/document-1234/#go-aws-sso)\n\n    This tool lets you interactively (or directly) select the account and role you want credentials for. It has no external dependencies and ships as a pre-built binary for your platform. You may install the tool via a homebrew tap, downloading the binary, go install or from source. After installation, just run go-aws-sso . At first time usage, you will be prompted for your SSO Start URL and your region (those values will be stored in a separate config file) * idealo start URL: https://idealo-login.awsapps.com/start#/ * idealo default region: eu-central-1 Now you can select your account and role.\n    \n    Prolong session durations\n\n    Backstage link: [Prolong session durations](https://backstage-stg.idealo.tools/document-1234/#prolong-session-durations)\n\n    If the default session duration of 1h is to short, you can prolong this duration by following this guide .\n    \n    Access accounts cloudtrail logs\n\n    Backstage link: [Access accounts cloudtrail logs](https://backstage-stg.idealo.tools/document-1234/#access-accounts-cloudtrail-logs)\n\n    Cloudtrail logs contain every event that happens in your account. How to search/access that logs is described here .\n    \n    Management\n    \n    Moving an account to another KOMUEB\n\n    Backstage link: [Moving an account to another KOMUEB](https://backstage-stg.idealo.tools/document-1234/#moving-an-account-to-another-komueb)\n\n    This can't be done by just a PR. Manually work is required to accomplish this task. The reason is that the TF state files are stored in S3 and simply moving the files would cause the deletion of the corresponding account(s). To move an account to another KOMUEB just follow these steps: Set the permission from it-all to Read Disable all workflows in the repository (you can simply do that with the GitHub web ui) Log into the Organisation Management account and move in S3 the tf state file to the new location (the tf states are located in the bucket idealo-prod-org-tg-state ) Move in the repository the account file (and eventually permission sets) to the new KOMUEB folder. Create a PR and finally merge it (no action SHOULD be triggered) Re-enable all GitHub workflows again Finally, change the field komueb_product_ticket in the moved account file, create a PR and merge it as normal Set it-all back to Write again\n    \n    AWS Account Closure Process\n\n    Backstage link: [AWS Account Closure Process](https://backstage-stg.idealo.tools/document-1234/account-closure/)\n\n    AWS Account Closure Process ¶ AWS Account Closure from AWS' Perspective ¶ (Source: https://miro.com/app/board/o9J_lxbRomI=/ ) Additional Resources: * Closing an AWS account * Closing an AWS Organizations member account AWS Account Closure Step by Step Guide ¶ Delete Resources ¶ [!NOTE] The following tasks have to be done by the account owners team: Delete all of your resources within the account Org-managed resources (e.g. CloudTrail) will automatically be deleted later on Resources may still incur costs in certain scenarios Resources cannot be deleted/terminated during the post-closure period Cancel Subscriptions ¶ [!NOTE] The following tasks have to be done by the account owners team: Cancel all marketplace subscriptions within your account Subscription may still incur costs, even after closure until the end of the post-closure period and beyond Marketplace subscriptions cannot be canceled during the post-closure period Close Account ¶ [!NOTE] The following tasks have to be done by the account owner: Create a pull request in the aws-accounts repo, deleting the terragrunt.hcl configuration for the account you want to close The 90-day post-closure period begins after the pull request was merged Remove Account Root Email Address from Active Directory ¶ [!NOTE] The following tasks have to be done by the account owner: Go to https://idealo-grpmgmt-prod.azurewebsites.net/# You have to be group owner for that. Since you are account owner, this should hopefully be the case Delete the group of the root account's email address (for non idealo-org accounts make sure it's not used in another context)\n    \n    AWS Account Closure Process\n    \n    AWS Account Closure from AWS' Perspective\n\n    Backstage link: [AWS Account Closure from AWS' Perspective](https://backstage-stg.idealo.tools/document-1234/account-closure/#aws-account-closure-from-aws-perspective)\n\n    (Source: https://miro.com/app/board/o9J_lxbRomI=/ ) Additional Resources: * Closing an AWS account * Closing an AWS Organizations member account\n    \n    AWS Account Closure Step by Step Guide\n    \n    Delete Resources\n\n    Backstage link: [Delete Resources](https://backstage-stg.idealo.tools/document-1234/account-closure/#delete-resources)\n\n    [!NOTE] The following tasks have to be done by the account owners team: Delete all of your resources within the account Org-managed resources (e.g. CloudTrail) will automatically be deleted later on Resources may still incur costs in certain scenarios Resources cannot be deleted/terminated during the post-closure period\n    \n    Cancel Subscriptions\n\n    Backstage link: [Cancel Subscriptions](https://backstage-stg.idealo.tools/document-1234/account-closure/#cancel-subscriptions)\n\n    [!NOTE] The following tasks have to be done by the account owners team: Cancel all marketplace subscriptions within your account Subscription may still incur costs, even after closure until the end of the post-closure period and beyond Marketplace subscriptions cannot be canceled during the post-closure period\n    \n    Close Account\n\n    Backstage link: [Close Account](https://backstage-stg.idealo.tools/document-1234/account-closure/#close-account)\n\n    [!NOTE] The following tasks have to be done by the account owner: Create a pull request in the aws-accounts repo, deleting the terragrunt.hcl configuration for the account you want to close The 90-day post-closure period begins after the pull request was merged\n    \n    Remove Account Root Email Address from Active Directory\n\n    Backstage link: [Remove Account Root Email Address from Active Directory](https://backstage-stg.idealo.tools/document-1234/account-closure/#remove-account-root-email-address-from-active-directory)\n\n    [!NOTE] The following tasks have to be done by the account owner: Go to https://idealo-grpmgmt-prod.azurewebsites.net/# You have to be group owner for that. Since you are account owner, this should hopefully be the case Delete the group of the root account's email address (for non idealo-org accounts make sure it's not used in another context)\n    \n    AWS Account Slicing Guidelines\n\n    Backstage link: [AWS Account Slicing Guidelines](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/)\n\n    AWS Account Slicing Guidelines ¶ Note: Workload and SDLC accounts SHOULD be sliced after subdomains only (one production account per subdomain) Each account MUST clearly be assigned to one team (no shared ownership) In some corner cases it might make sense to have multiple productive AWS accounts per Subdomain. Please talk to the Engineering Experience Team, if you see this need. Sandbox accounts may be sliced differently (e.g. per team, per individual) and SHOULD be nuked daily. Reasoning ¶ As described here , teams in PT are #end-to-end-responsible for one or more subdomains. These subdomains mark clear borders of responsibility: Teams are responsible for maintaining, securing and operating the implementation of their subdomain(s) in software (the system). The borders of this system must match the borders of the according subdomain. Only this way the teams can be #end-to-end-responsible for their part of the overall system. This goes hand-in-hand with the decentralised data protection mechanism we follow at idealo. The responsible team for a certain domain is responsible for protecting the data processed and stored in their subdomain. We document this by linking each subdomain to a product in the Verfahrensverzeichnis . Each product in the Verfahrensverzeichnis has a 1-to-1 relationship with the according subdomain. AWS accounts are a perfect match for these borders of responsibilities in AWS. The responsible team for the subdomain / account has everything in their hands to operate their subdomain in this AWS account. With AWS IAM the team has everything in their hands to protect processed and stored data of this subdomain and grant access to this data in a decentralised way. In the Verfahrensverzeichnis the AWS account itself is documented as a technical component of the product / subdomain. This makes it potentially possible to have multiple AWS accounts per subdomain, which come at a price and should be avoided in most cases. Implications of this decision ¶ AWS account slicing after subdomains is a perfect fit for our decentralised data protection approach and our guiding principles #domain-driven and #end-to-end-responsibility PA accounts or shared accounts between teams is not possible any longer If a team uses an IaC product, this product should be instantiated and kept up-to-date by the team who owns the account. These deployments and the operations should be as smooth as possible. It’s also OK that a team operates an IaC product for e.g. the whole PA and gives them access as long as the shared responsibility (e.g. in terms of data protection) is clearly defined. FAQ ¶ Subdomains ¶ How do we identify our subdomains? If you struggle to find good subdomains, don’t panic. Subdomains must not be perfect at first shot. If you need help defining your subdomain, you can ask the #domain-driven Guiding Principle guards ( Krister Saleck , Christoph Korn ) to help you with that. If you really do not find a good subdomain, please: At least create one account per team, but do name the account after what the team is doing and not after the team name. Do not take the current products in the Verfahrensverzeichnis as granted. First define your subdomain and derive from that what goes as product in the Verfahrensverzeichnis. What about platform subdomains? In general we differentiate between value stream aligned, complicated subsystem and platform subdomains. This account slicing proposal refers to all three of these. So to make it clear: We also see AWS accounts for centrally operated platform services. What about IaC platform products? Do they need their own AWS account then? No, we rather think that IaC products should be instantiated in the subdomain AWS accounts that use these products. Subdomain overarching concerns ¶ What about virtual teams/focus groups? Can they own an AWS account? As long as a PO or a HoX is accountable for this account (mentioned as accountable in the Verfahrensverzeichnis), it should be OK, that the owning team is a virtual team. However, please clarify this with Andreas Jentsch or Mike Lesniak in each case beforehand. Can we give cross-team on-call access to accounts? Every owning team can give another team or single persons access to their account. Still, the owning team remains responsible for the account as well as keeping track of access. Can a team operate their own cross-domain “infrastructure account”? In rare cases, a responsible team may have an account dedicated to their cross-domain infrastructure products, if absolutely necessary. However, this is not recommended. Try to keep infrastructure required for your subdomain with your subdomain apps in the same account. Also, think about your subdomains. If multiple subdomains in your responsibility use the same things, e.g. data, these same things may indeed represent their own subdomain. Can we keep our PA account (e.g with our logging stack), as long as we have services in the DC? In the new AWS organisation we don’t want to have PA accounts. As long as the account can stay in the AWS organisation of Axel Springer, we may keep it as a PA account. However, as soon as we need to move out of the Axel Springer organisation, we have to find another solution (e.g. a designated team and accountable owner in the PA). Can we keep our PA account in the new AWS organisation? No. Please find another solution, e.g. a designated (virtual) team and accountable owner in the PA that owns certain things and offers these as a service in an AWS account. Responsibilities ¶ Who is the person that is accountable for an AWS account? The single person that is accountable for an AWS account is the one mentioned as accountable in the Verfahrensverzeichnis for the corresponding product. This needs to be either a PO, a HoP, or a HoT. Who is the team that is owning an AWS account? The default is that ownership of AWS accounts belongs to teams as per the organisational structure. However, for some rare subdomain overarching concerns “virtual teams” may also assume this role if responsibility is taken, team membership is clear, and a designated accountable person is defined. Sandbox / Playground accounts ¶ Do we need a KOMUEB-Ticket (sub-domain) for a sandbox/playground account? No you don’t need your own KOMUEB-Ticket. All Sandbox accounts are linked to a generic sandbox ticket. Please use this one: KOMUEB-3188 Prerequisites ¶ What do we need for an AWS account? You need an entry in the Verfahrensverzeichnis for your subdomain. This can be a part of a business domain or an infrastructure/platform product You need an accountable person. This must be a PO or a HoT/HoP You need the cost center of your PA\n    \n    AWS Account Slicing Guidelines\n\n    Backstage link: [AWS Account Slicing Guidelines](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#aws-account-slicing-guidelines)\n\n    Note: Workload and SDLC accounts SHOULD be sliced after subdomains only (one production account per subdomain) Each account MUST clearly be assigned to one team (no shared ownership) In some corner cases it might make sense to have multiple productive AWS accounts per Subdomain. Please talk to the Engineering Experience Team, if you see this need. Sandbox accounts may be sliced differently (e.g. per team, per individual) and SHOULD be nuked daily.\n    \n    Reasoning\n\n    Backstage link: [Reasoning](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#reasoning)\n\n    As described here , teams in PT are #end-to-end-responsible for one or more subdomains. These subdomains mark clear borders of responsibility: Teams are responsible for maintaining, securing and operating the implementation of their subdomain(s) in software (the system). The borders of this system must match the borders of the according subdomain. Only this way the teams can be #end-to-end-responsible for their part of the overall system. This goes hand-in-hand with the decentralised data protection mechanism we follow at idealo. The responsible team for a certain domain is responsible for protecting the data processed and stored in their subdomain. We document this by linking each subdomain to a product in the Verfahrensverzeichnis . Each product in the Verfahrensverzeichnis has a 1-to-1 relationship with the according subdomain. AWS accounts are a perfect match for these borders of responsibilities in AWS. The responsible team for the subdomain / account has everything in their hands to operate their subdomain in this AWS account. With AWS IAM the team has everything in their hands to protect processed and stored data of this subdomain and grant access to this data in a decentralised way. In the Verfahrensverzeichnis the AWS account itself is documented as a technical component of the product / subdomain. This makes it potentially possible to have multiple AWS accounts per subdomain, which come at a price and should be avoided in most cases.\n    \n    Implications of this decision\n\n    Backstage link: [Implications of this decision](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#implications-of-this-decision)\n\n    AWS account slicing after subdomains is a perfect fit for our decentralised data protection approach and our guiding principles #domain-driven and #end-to-end-responsibility PA accounts or shared accounts between teams is not possible any longer If a team uses an IaC product, this product should be instantiated and kept up-to-date by the team who owns the account. These deployments and the operations should be as smooth as possible. It’s also OK that a team operates an IaC product for e.g. the whole PA and gives them access as long as the shared responsibility (e.g. in terms of data protection) is clearly defined.\n    \n    FAQ\n    \n    Subdomains\n\n    Backstage link: [Subdomains](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#subdomains)\n\n    How do we identify our subdomains? If you struggle to find good subdomains, don’t panic. Subdomains must not be perfect at first shot. If you need help defining your subdomain, you can ask the #domain-driven Guiding Principle guards ( Krister Saleck , Christoph Korn ) to help you with that. If you really do not find a good subdomain, please: At least create one account per team, but do name the account after what the team is doing and not after the team name. Do not take the current products in the Verfahrensverzeichnis as granted. First define your subdomain and derive from that what goes as product in the Verfahrensverzeichnis. What about platform subdomains? In general we differentiate between value stream aligned, complicated subsystem and platform subdomains. This account slicing proposal refers to all three of these. So to make it clear: We also see AWS accounts for centrally operated platform services. What about IaC platform products? Do they need their own AWS account then? No, we rather think that IaC products should be instantiated in the subdomain AWS accounts that use these products.\n    \n    Subdomain overarching concerns\n\n    Backstage link: [Subdomain overarching concerns](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#subdomain-overarching-concerns)\n\n    What about virtual teams/focus groups? Can they own an AWS account? As long as a PO or a HoX is accountable for this account (mentioned as accountable in the Verfahrensverzeichnis), it should be OK, that the owning team is a virtual team. However, please clarify this with Andreas Jentsch or Mike Lesniak in each case beforehand. Can we give cross-team on-call access to accounts? Every owning team can give another team or single persons access to their account. Still, the owning team remains responsible for the account as well as keeping track of access. Can a team operate their own cross-domain “infrastructure account”? In rare cases, a responsible team may have an account dedicated to their cross-domain infrastructure products, if absolutely necessary. However, this is not recommended. Try to keep infrastructure required for your subdomain with your subdomain apps in the same account. Also, think about your subdomains. If multiple subdomains in your responsibility use the same things, e.g. data, these same things may indeed represent their own subdomain. Can we keep our PA account (e.g with our logging stack), as long as we have services in the DC? In the new AWS organisation we don’t want to have PA accounts. As long as the account can stay in the AWS organisation of Axel Springer, we may keep it as a PA account. However, as soon as we need to move out of the Axel Springer organisation, we have to find another solution (e.g. a designated team and accountable owner in the PA). Can we keep our PA account in the new AWS organisation? No. Please find another solution, e.g. a designated (virtual) team and accountable owner in the PA that owns certain things and offers these as a service in an AWS account.\n    \n    Responsibilities\n\n    Backstage link: [Responsibilities](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#responsibilities)\n\n    Who is the person that is accountable for an AWS account? The single person that is accountable for an AWS account is the one mentioned as accountable in the Verfahrensverzeichnis for the corresponding product. This needs to be either a PO, a HoP, or a HoT. Who is the team that is owning an AWS account? The default is that ownership of AWS accounts belongs to teams as per the organisational structure. However, for some rare subdomain overarching concerns “virtual teams” may also assume this role if responsibility is taken, team membership is clear, and a designated accountable person is defined.\n    \n    Sandbox / Playground accounts\n\n    Backstage link: [Sandbox / Playground accounts](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#sandbox-playground-accounts)\n\n    Do we need a KOMUEB-Ticket (sub-domain) for a sandbox/playground account? No you don’t need your own KOMUEB-Ticket. All Sandbox accounts are linked to a generic sandbox ticket. Please use this one: KOMUEB-3188\n    \n    Prerequisites\n\n    Backstage link: [Prerequisites](https://backstage-stg.idealo.tools/document-1234/account-slicing-guidelines/#prerequisites)\n\n    What do we need for an AWS account? You need an entry in the Verfahrensverzeichnis for your subdomain. This can be a part of a business domain or an infrastructure/platform product You need an accountable person. This must be a PO or a HoT/HoP You need the cost center of your PA\n    \n    CloudTrail logs\n\n    Backstage link: [CloudTrail logs](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/)\n\n    CloudTrail logs ¶ Cloudtrail logs are active for every account. They log all the events which are take place and store them finally in a S3 bucket in the central log archive account. In your own account you only had access to cloudtrail itself but not to the stored logs itself. Because it could be very cumbersome to find something in cloudtrail itself, we implemented the access to your accounts cloudtrail logs via the query engine Athena. [!NOTE] You can only view logs in eu-central-1, eu-west-1 and us-east-1 regions. How a cloudtrail entry looks like ¶ Here is a example when a user is logging into a account. The main field names are always the same. If a event just don't have data for a specific field, it is null . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \"eventVersion\" : \"1.08\" , \"userIdentity\" : { \"type\" : \"AssumedRole\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU:john.doe@idealo.de\" , \"arn\" : \"arn:aws:sts::187437750615:assumed-role/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802/john.doe@idealo.de\" , \"accountId\" : \"187437750615\" , \"sessionContext\" : { \"sessionIssuer\" : { \"type\" : \"Role\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU\" , \"arn\" : \"arn:aws:iam::187437750615:role/aws-reserved/sso.amazonaws.com/eu-central-1/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" , \"accountId\" : \"187437750615\" , \"userName\" : \"AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" }, \"webIdFederationData\" : {}, \"attributes\" : { \"creationDate\" : \"2022-10-11T11:48:42Z\" , \"mfaAuthenticated\" : \"false\" } } }, \"eventTime\" : \"2022-10-11T11:48:43Z\" , \"eventSource\" : \"signin.amazonaws.com\" , \"eventName\" : \"ConsoleLogin\" , \"awsRegion\" : \"eu-central-1\" , \"sourceIPAddress\" : \"95.90.235.41\" , \"userAgent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\" , \"requestParameters\" : null , \"responseElements\" : { \"ConsoleLogin\" : \"Success\" }, \"additionalEventData\" : { \"MobileVersion\" : \"No\" , \"MFAUsed\" : \"No\" }, \"eventID\" : \"31d91c11-44e7-4745-99f1-49e81d3a452a\" , \"readOnly\" : false , \"eventType\" : \"AwsConsoleSignIn\" , \"managementEvent\" : true , \"recipientAccountId\" : \"187437750615\" , \"eventCategory\" : \"Management\" , \"tlsDetails\" : { \"tlsVersion\" : \"TLSv1.2\" , \"cipherSuite\" : \"ECDHE-RSA-AES128-GCM-SHA256\" , \"clientProvidedHostHeader\" : \"eu-central-1.signin.aws.amazon.com\" } } Use SELECT to find entries ¶ So lets take the example above and try to find that now with athena. For that just go via the console to athena and select the database cloudtrail . In that database the table of interest is logs . [!NOTE] In athena you need to specify a S3 bucket where query results should be written to. If not already done, just define that bucket under Settings in Query result location. Before we start there a some things to note: The data is partioned by days from the 2022/01/06 on and the corresponding field is named timestamp . So if you want to isolate the results more, you need to work on the field eventTime If you want to access subfields you have to work with the dot notation (will be shown in the example) Ok, lets assume you want to find the account logins from a specific user on a specific day: 1 SELECT * FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ; The result coud be unreadable for you, since every information of the whole subfields are squeezed into a single line, like userIdentity for example. To shrink the result to the informations you need/want, just define the fields of interest in the query. To see all available table fields just press in the aws athena console the + icon left from the table name (logs) or see the JSON example above. 1 SELECT eventtime , sourceipaddress FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ; Define time ranges ¶ Sometimes it might be helpful to define timeranges for the search in regards to days or intraday times. You can achieve that with the following syntaxes. [!NOTE] On single digit day numbers work with a leading 0 Use placeholders in dates ¶ 1 2 WHERE timestamp like '2022/09/1%' WHERE timestamp like '2022/10/2%' Use a date range ¶ 1 WHERE timestamp >= '2022/10/09' AND timestamp <= '2022/10/10' Use time filtering ¶ 1 WHERE eventtime >= '2022-10-11T10:00' AND timestamp = '2022/10/11' Related links ¶ AWS documentation of SELECT in athena\n    \n    CloudTrail logs\n\n    Backstage link: [CloudTrail logs](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#cloudtrail-logs)\n\n    Cloudtrail logs are active for every account. They log all the events which are take place and store them finally in a S3 bucket in the central log archive account. In your own account you only had access to cloudtrail itself but not to the stored logs itself. Because it could be very cumbersome to find something in cloudtrail itself, we implemented the access to your accounts cloudtrail logs via the query engine Athena. [!NOTE] You can only view logs in eu-central-1, eu-west-1 and us-east-1 regions.\n    \n    How a cloudtrail entry looks like\n\n    Backstage link: [How a cloudtrail entry looks like](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#how-a-cloudtrail-entry-looks-like)\n\n    Here is a example when a user is logging into a account. The main field names are always the same. If a event just don't have data for a specific field, it is null . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \"eventVersion\" : \"1.08\" , \"userIdentity\" : { \"type\" : \"AssumedRole\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU:john.doe@idealo.de\" , \"arn\" : \"arn:aws:sts::187437750615:assumed-role/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802/john.doe@idealo.de\" , \"accountId\" : \"187437750615\" , \"sessionContext\" : { \"sessionIssuer\" : { \"type\" : \"Role\" , \"principalId\" : \"AROASXJBJDFLZ4BWG35GU\" , \"arn\" : \"arn:aws:iam::187437750615:role/aws-reserved/sso.amazonaws.com/eu-central-1/AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" , \"accountId\" : \"187437750615\" , \"userName\" : \"AWSReservedSSO_AWSAdministratorAccess8h_a9b9ddb5199ab802\" }, \"webIdFederationData\" : {}, \"attributes\" : { \"creationDate\" : \"2022-10-11T11:48:42Z\" , \"mfaAuthenticated\" : \"false\" } } }, \"eventTime\" : \"2022-10-11T11:48:43Z\" , \"eventSource\" : \"signin.amazonaws.com\" , \"eventName\" : \"ConsoleLogin\" , \"awsRegion\" : \"eu-central-1\" , \"sourceIPAddress\" : \"95.90.235.41\" , \"userAgent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\" , \"requestParameters\" : null , \"responseElements\" : { \"ConsoleLogin\" : \"Success\" }, \"additionalEventData\" : { \"MobileVersion\" : \"No\" , \"MFAUsed\" : \"No\" }, \"eventID\" : \"31d91c11-44e7-4745-99f1-49e81d3a452a\" , \"readOnly\" : false , \"eventType\" : \"AwsConsoleSignIn\" , \"managementEvent\" : true , \"recipientAccountId\" : \"187437750615\" , \"eventCategory\" : \"Management\" , \"tlsDetails\" : { \"tlsVersion\" : \"TLSv1.2\" , \"cipherSuite\" : \"ECDHE-RSA-AES128-GCM-SHA256\" , \"clientProvidedHostHeader\" : \"eu-central-1.signin.aws.amazon.com\" } }\n    \n    Use SELECT to find entries\n\n    Backstage link: [Use SELECT to find entries](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#use-select-to-find-entries)\n\n    So lets take the example above and try to find that now with athena. For that just go via the console to athena and select the database cloudtrail . In that database the table of interest is logs . [!NOTE] In athena you need to specify a S3 bucket where query results should be written to. If not already done, just define that bucket under Settings in Query result location. Before we start there a some things to note: The data is partioned by days from the 2022/01/06 on and the corresponding field is named timestamp . So if you want to isolate the results more, you need to work on the field eventTime If you want to access subfields you have to work with the dot notation (will be shown in the example) Ok, lets assume you want to find the account logins from a specific user on a specific day: 1 SELECT * FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ; The result coud be unreadable for you, since every information of the whole subfields are squeezed into a single line, like userIdentity for example. To shrink the result to the informations you need/want, just define the fields of interest in the query. To see all available table fields just press in the aws athena console the + icon left from the table name (logs) or see the JSON example above. 1 SELECT eventtime , sourceipaddress FROM logs WHERE eventtype = 'AwsConsoleSignIn' AND useridentity . arn like '%john.doe%' AND timestamp like '2022/10/11' AND account_id = '<your-aws-account-id>' LIMIT 10 ;\n    \n    Define time ranges\n\n    Backstage link: [Define time ranges](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#define-time-ranges)\n\n    Sometimes it might be helpful to define timeranges for the search in regards to days or intraday times. You can achieve that with the following syntaxes. [!NOTE] On single digit day numbers work with a leading 0\n    \n    Use placeholders in dates\n\n    Backstage link: [Use placeholders in dates](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#use-placeholders-in-dates)\n\n    1 2 WHERE timestamp like '2022/09/1%' WHERE timestamp like '2022/10/2%'\n    \n    Use a date range\n\n    Backstage link: [Use a date range](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#use-a-date-range)\n\n    1 WHERE timestamp >= '2022/10/09' AND timestamp <= '2022/10/10'\n    \n    Use time filtering\n\n    Backstage link: [Use time filtering](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#use-time-filtering)\n\n    1 WHERE eventtime >= '2022-10-11T10:00' AND timestamp = '2022/10/11'\n    \n    Related links\n\n    Backstage link: [Related links](https://backstage-stg.idealo.tools/document-1234/cloudtrail-logs/#related-links)\n\n    AWS documentation of SELECT in athena\n    \n    Local development\n\n    Backstage link: [Local development](https://backstage-stg.idealo.tools/document-1234/local-development/)\n\n    Local development ¶ This documentation is only for the owners and maintainers of the aws organization. Local execution ¶ To plan and/or apply changes locally you need to expose the following key/values that are needed to execute the IaC: 1 2 3 4 5 6 7 export JIRA_PAT_TOKEN= export JIRA_CUSTOM_AUTH_HEADER_KEY= export JIRA_CUSTOM_AUTH_HEADER_VALUE= export GROUP_CREATOR_KEY= export MS_CLIENT_ID= export MS_CLIENT_SECRET= export MS_ROBOT_PASSWORD= Some values can be found in 1Password. The entry aws-accounts env variables for prod-org contains the complete list of key/values.\n    \n    Local development\n\n    Backstage link: [Local development](https://backstage-stg.idealo.tools/document-1234/local-development/#local-development)\n\n    This documentation is only for the owners and maintainers of the aws organization.\n    \n    Local execution\n\n    Backstage link: [Local execution](https://backstage-stg.idealo.tools/document-1234/local-development/#local-execution)\n\n    To plan and/or apply changes locally you need to expose the following key/values that are needed to execute the IaC: 1 2 3 4 5 6 7 export JIRA_PAT_TOKEN= export JIRA_CUSTOM_AUTH_HEADER_KEY= export JIRA_CUSTOM_AUTH_HEADER_VALUE= export GROUP_CREATOR_KEY= export MS_CLIENT_ID= export MS_CLIENT_SECRET= export MS_ROBOT_PASSWORD= Some values can be found in 1Password. The entry aws-accounts env variables for prod-org contains the complete list of key/values.\n    \n    Sandbox Account Nuking 💥\n\n    Backstage link: [Sandbox Account Nuking 💥](https://backstage-stg.idealo.tools/document-1234/nuking-sandbox-accounts/)\n\n    Sandbox Account Nuking 💥 ¶ Sandbox accounts in our AWS organization will automatically delete all non-essential resources within themselves every night. This is achieved using rebuy-de/aws-nuke . If you have resources in the account that you would like to persist you may exclude them by providing your own filter config. Filtering Resources 🪣 ¶ Observe the resources that are deleted and their names in the logs of the NukeProject runs in CodeBuild Write your own config to exclude the objects that you'd like to keep ( config reference ), for example: 1 2 3 4 5 accounts : REPLACE-WITH-YOUR-ACCOUNT-ID : filters : S3Bucket : - my-favorite-bucket If you want to exclude you whole account from nuking you can use the following configuration: 1 2 account-blocklist : - \"REPLACE-WITH-YOUR-ACCOUNT-ID\" Upload this into the -nuke-configs S3 bucket in your sandbox account. The file needs to end in .yml to be considered. Any changes to the existing DO-NOT-EDIT-managed-config.yml will be overridden, so make sure to create your own additional file: You can test your config by manually triggering a nuke run in CodeBuild [!NOTE] You can also specify and override other config options of aws-nuke - all .yml files in the bucket are merged together to one config. Arrays will be appended to each other during merging Temporarly Disabling AWS Nuke 🚯 ¶ If you like to temporarly disable nuking due to testing purposes, you may do so in the AWS Console. Go to your AWS Console EventBridge Rules StackSet-AccountNuking[...] Disable Done ☑️ Please be aware, that you will get every morning a warning e-Mail, stating that your nuke is not running as expected.\n    \n    Sandbox Account Nuking 💥\n\n    Backstage link: [Sandbox Account Nuking 💥](https://backstage-stg.idealo.tools/document-1234/nuking-sandbox-accounts/#sandbox-account-nuking)\n\n    Sandbox accounts in our AWS organization will automatically delete all non-essential resources within themselves every night. This is achieved using rebuy-de/aws-nuke . If you have resources in the account that you would like to persist you may exclude them by providing your own filter config.\n    \n    Filtering Resources 🪣\n\n    Backstage link: [Filtering Resources 🪣](https://backstage-stg.idealo.tools/document-1234/nuking-sandbox-accounts/#filtering-resources)\n\n    Observe the resources that are deleted and their names in the logs of the NukeProject runs in CodeBuild Write your own config to exclude the objects that you'd like to keep ( config reference ), for example: 1 2 3 4 5 accounts : REPLACE-WITH-YOUR-ACCOUNT-ID : filters : S3Bucket : - my-favorite-bucket If you want to exclude you whole account from nuking you can use the following configuration: 1 2 account-blocklist : - \"REPLACE-WITH-YOUR-ACCOUNT-ID\" Upload this into the -nuke-configs S3 bucket in your sandbox account. The file needs to end in .yml to be considered. Any changes to the existing DO-NOT-EDIT-managed-config.yml will be overridden, so make sure to create your own additional file: You can test your config by manually triggering a nuke run in CodeBuild [!NOTE] You can also specify and override other config options of aws-nuke - all .yml files in the bucket are merged together to one config. Arrays will be appended to each other during merging\n    \n    Temporarly Disabling AWS Nuke 🚯\n\n    Backstage link: [Temporarly Disabling AWS Nuke 🚯](https://backstage-stg.idealo.tools/document-1234/nuking-sandbox-accounts/#temporarly-disabling-aws-nuke)\n\n    If you like to temporarly disable nuking due to testing purposes, you may do so in the AWS Console. Go to your AWS Console EventBridge Rules StackSet-AccountNuking[...] Disable Done ☑️ Please be aware, that you will get every morning a warning e-Mail, stating that your nuke is not running as expected.\n    \n    How to prolong the session duration\n\n    Backstage link: [How to prolong the session duration](https://backstage-stg.idealo.tools/document-1234/prolong-session-duration/)\n\n    How to prolong the session duration ¶ Preface ¶ Per default every permissionset comes with a default session duration of 1 hour. In most use cases this is enough, but in some other it is not. Therefore you have the possibility to prolong the session duration to 8 hours. The following sections shows you 2 way how to do that. Preconditions ¶ First you need to make sure that a corresponding risk ticket for the prolongation of the session duration to 8h is in place: 1. For non-prod accounts (sandbox & SDLC) there is no need to create a risk ticket as you can use the following already accepted one RISK-111129 2. For prod accounts you need to create one (You can take this ticket as a template, but don't forget to alter non-production to production there, since it was initially meant for non-production accounts). Further this ticket needs to be accepted by your PO, TL or HoX and the status must be set to RISK ACCEPTED . Afterwards the security team will review the ticket and set the status to RISK ACCEPTANCE APPROVED If point 1. is complete you have to make a pull request to this repository on github using one of the described solutions from the next chapter and put the link of the corresponding risk ticket into that PR Option 1: Use a predefined permission set ¶ The EXT prepared for the 3 most used permission sets ( AWSAdministratorAccess , AWSReadOnlyAccess and AWSPowerUserAccess ) an alternative with a session duration of 8h. For using this just change the option group_permissions in the corresponding terragrunt.hcl accordingly and replace the occurence of the 3 mentioned permission sets with either one of the following: AWSAdministratorAccess8h AWSReadOnlyAccess8h AWSPowerUserAccess8h Example: 1 2 3 4 5 group_permissions = { \"MyADGroup1\" = [\"AWSAdministratorAccess8h\"] \"MyADGroup2\" = [\"AWSReadOnlyAccess8h\"] \"MyADGroup3\" = [\"AWSPowerUserAccess8h\"] } Option 2: Write your own or extend your existing permission set ¶ Beside the predefined permission sets you have the option to write your own permission sets. Some of you already made use of that. A example of a account definition with a self defined permission set can be found here . Just make use of session_duration in the terragrunt.hcl file in the corresponding permission set folder and set the value to PT8H : 1 2 3 inputs = { session_duration = \"PT8H\" ... [!NOTE] Please be aware that only the values PT1H or PT8H are allowed. If the option is missing, PT1H is the default.\n    \n    How to prolong the session duration\n    \n    Preface\n\n    Backstage link: [Preface](https://backstage-stg.idealo.tools/document-1234/prolong-session-duration/#preface)\n\n    Per default every permissionset comes with a default session duration of 1 hour. In most use cases this is enough, but in some other it is not. Therefore you have the possibility to prolong the session duration to 8 hours. The following sections shows you 2 way how to do that.\n    \n    Preconditions\n\n    Backstage link: [Preconditions](https://backstage-stg.idealo.tools/document-1234/prolong-session-duration/#preconditions)\n\n    First you need to make sure that a corresponding risk ticket for the prolongation of the session duration to 8h is in place: 1. For non-prod accounts (sandbox & SDLC) there is no need to create a risk ticket as you can use the following already accepted one RISK-111129 2. For prod accounts you need to create one (You can take this ticket as a template, but don't forget to alter non-production to production there, since it was initially meant for non-production accounts). Further this ticket needs to be accepted by your PO, TL or HoX and the status must be set to RISK ACCEPTED . Afterwards the security team will review the ticket and set the status to RISK ACCEPTANCE APPROVED If point 1. is complete you have to make a pull request to this repository on github using one of the described solutions from the next chapter and put the link of the corresponding risk ticket into that PR\n    \n    Option 1: Use a predefined permission set\n\n    Backstage link: [Option 1: Use a predefined permission set](https://backstage-stg.idealo.tools/document-1234/prolong-session-duration/#option-1-use-a-predefined-permission-set)\n\n    The EXT prepared for the 3 most used permission sets ( AWSAdministratorAccess , AWSReadOnlyAccess and AWSPowerUserAccess ) an alternative with a session duration of 8h. For using this just change the option group_permissions in the corresponding terragrunt.hcl accordingly and replace the occurence of the 3 mentioned permission sets with either one of the following: AWSAdministratorAccess8h AWSReadOnlyAccess8h AWSPowerUserAccess8h Example: 1 2 3 4 5 group_permissions = { \"MyADGroup1\" = [\"AWSAdministratorAccess8h\"] \"MyADGroup2\" = [\"AWSReadOnlyAccess8h\"] \"MyADGroup3\" = [\"AWSPowerUserAccess8h\"] }\n    \n    Option 2: Write your own or extend your existing permission set\n\n    Backstage link: [Option 2: Write your own or extend your existing permission set](https://backstage-stg.idealo.tools/document-1234/prolong-session-duration/#option-2-write-your-own-or-extend-your-existing-permission-set)\n\n    Beside the predefined permission sets you have the option to write your own permission sets. Some of you already made use of that. A example of a account definition with a self defined permission set can be found here . Just make use of session_duration in the terragrunt.hcl file in the corresponding permission set folder and set the value to PT8H : 1 2 3 inputs = { session_duration = \"PT8H\" ... [!NOTE] Please be aware that only the values PT1H or PT8H are allowed. If the option is missing, PT1H is the default.\n    \n    Renaming AWS Account\n\n    Backstage link: [Renaming AWS Account](https://backstage-stg.idealo.tools/document-1234/renaming-aws-account/)\n\n    Renaming AWS Account ¶ This page is supposed to serve as a quick guide for the steps required when renaming an AWS account managed by Control Tower in the idealo org. The procedure is rather involved. That's why you should consider closing an account and creating a new one over renaming it . However, if you still want to rename an account, follow the steps below. Disable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Create a new group for the new account email address in the GroupTool . - The email should be the account name with all spaces and special characters replaced by a minus (-), prefixed by aws. (example: aws.my-account@idealo.de ) - Owners should follow the process of enabling external emails and following the inbox like required for new accounts. Login to the AWS account with root user credentials. - If no credentials have been set for the account they should use the \"Forgot Password\" process. - Make sure that receiving external emails is allowed for the old account email group (aws.account-name). Navigate to \"Account\" from the top right dropdown menu (where it says the account name). Click on \"Edit\" in the Account Settings section. In the resulting form, update both name and email, then save. - The name should be less than 30 characters long. (example: My Account) - The email needs to match the previously created group exactly. Log out of the AWS account. Re-enable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Terminate the AWS Service Catalog Provisioned Product for the account (name with special chars and spaces replaced by underscores, e.g. Account_Name). - This will not close the account - it will just un-manage it in Control Tower and move it outside the OU. Once this is done, go to AWS Organizations and move the account into the Transitional OU (so that the AWSControlTowerExecution role is re-created via StackSet). This is important! Ensure the role was indeed re-created. Switch into the account and make sure all resources have been cleaned up. - No CloudFormation stacks from our org StackSets are left in progress or in DELETE_FAILED state in all 3 regions (eu-central-1, eu-west-1, us-east-1). 1 2 3 4 5 * This implies that you will be deleting VPCs deployed via Stack Sets. * This will also imply that you have to delete manually the s3 buckets created by the Stack Sets. * DNSZone StackSet: You may be required to temporarily re-enable the KMS CMK in us-east-1 to be able to disable Route53 Dnssec. Remember to schedule deletion again afterwards. - CloudWatch Logs Log Group \"/aws/lambda/aws-controltower-NotificationForwarder\" needs to be deleted in all 3 regions. Update the idealo/aws-accounts repository in a branch, changing the name of the account in the inputs and renaming its directory. - In case that the account has the root_email input defined, you can remove this input. Move the state file in the \"idealo-prod-org-tg-state\" S3 bucket in the Organization Management account to the correct new location. Drop the DynamoDB item for the old state path in the lock table \"idealo-prod-org-tg-lock\" . Submit PR to the idealo/aws-accounts repository with your changes and verify that the plans are correct. - It will detect a destroy of the old path - but that is fine as long as within the destroy plan you do not see any actual actions! - It is ok if the plan says it's about to create a new account though. In fact, it will not create it but rather move from the Transitional OU into the correct OU. - Make sure that none of the plans contain an account destroy! Merge the PR, let the workflows run and keep an eye on them. - Afterwards, you may want to double check if all stacks came up properly in the account via the AWSControlTowerExecution role.\n    \n    Renaming AWS Account\n\n    Backstage link: [Renaming AWS Account](https://backstage-stg.idealo.tools/document-1234/renaming-aws-account/#renaming-aws-account)\n\n    This page is supposed to serve as a quick guide for the steps required when renaming an AWS account managed by Control Tower in the idealo org. The procedure is rather involved. That's why you should consider closing an account and creating a new one over renaming it . However, if you still want to rename an account, follow the steps below. Disable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Create a new group for the new account email address in the GroupTool . - The email should be the account name with all spaces and special characters replaced by a minus (-), prefixed by aws. (example: aws.my-account@idealo.de ) - Owners should follow the process of enabling external emails and following the inbox like required for new accounts. Login to the AWS account with root user credentials. - If no credentials have been set for the account they should use the \"Forgot Password\" process. - Make sure that receiving external emails is allowed for the old account email group (aws.account-name). Navigate to \"Account\" from the top right dropdown menu (where it says the account name). Click on \"Edit\" in the Account Settings section. In the resulting form, update both name and email, then save. - The name should be less than 30 characters long. (example: My Account) - The email needs to match the previously created group exactly. Log out of the AWS account. Re-enable the guardrail \"Disallow actions as a root user\" on the organizational unit in which the account is in. Terminate the AWS Service Catalog Provisioned Product for the account (name with special chars and spaces replaced by underscores, e.g. Account_Name). - This will not close the account - it will just un-manage it in Control Tower and move it outside the OU. Once this is done, go to AWS Organizations and move the account into the Transitional OU (so that the AWSControlTowerExecution role is re-created via StackSet). This is important! Ensure the role was indeed re-created. Switch into the account and make sure all resources have been cleaned up. - No CloudFormation stacks from our org StackSets are left in progress or in DELETE_FAILED state in all 3 regions (eu-central-1, eu-west-1, us-east-1). 1 2 3 4 5 * This implies that you will be deleting VPCs deployed via Stack Sets. * This will also imply that you have to delete manually the s3 buckets created by the Stack Sets. * DNSZone StackSet: You may be required to temporarily re-enable the KMS CMK in us-east-1 to be able to disable Route53 Dnssec. Remember to schedule deletion again afterwards. - CloudWatch Logs Log Group \"/aws/lambda/aws-controltower-NotificationForwarder\" needs to be deleted in all 3 regions. Update the idealo/aws-accounts repository in a branch, changing the name of the account in the inputs and renaming its directory. - In case that the account has the root_email input defined, you can remove this input. Move the state file in the \"idealo-prod-org-tg-state\" S3 bucket in the Organization Management account to the correct new location. Drop the DynamoDB item for the old state path in the lock table \"idealo-prod-org-tg-lock\" . Submit PR to the idealo/aws-accounts repository with your changes and verify that the plans are correct. - It will detect a destroy of the old path - but that is fine as long as within the destroy plan you do not see any actual actions! - It is ok if the plan says it's about to create a new account though. In fact, it will not create it but rather move from the Transitional OU into the correct OU. - Make sure that none of the plans contain an account destroy! Merge the PR, let the workflows run and keep an eye on them. - Afterwards, you may want to double check if all stacks came up properly in the account via the AWSControlTowerExecution role.\n    "}